{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Cell 01\n",
    "%pip install -q  xgboost==1.3.1 pandas==1.0.5 --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 02\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import joblib\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner\n",
    ")\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "# Setting SageMaker variables\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\" \n",
    "\n",
    "\n",
    "# Setting S3 location for read and write operations\n",
    "train_data_key = f\"{read_prefix}/train.csv\"\n",
    "test_data_key = f\"{read_prefix}/test.csv\"\n",
    "validation_data_key = f\"{read_prefix}/validation.csv\"\n",
    "model_key = f\"{write_prefix}/model\"\n",
    "output_key = f\"{write_prefix}/output\"\n",
    "\n",
    "\n",
    "train_data_uri = f\"s3://{read_bucket}/{train_data_key}\"\n",
    "test_data_uri = f\"s3://{read_bucket}/{test_data_key}\"\n",
    "validation_data_uri = f\"s3://{read_bucket}/{validation_data_key}\"\n",
    "model_uri = f\"s3://{write_bucket}/{model_key}\"\n",
    "output_uri = f\"s3://{write_bucket}/{output_key}\"\n",
    "estimator_output_uri = f\"s3://{write_bucket}/{write_prefix}/training_jobs\"\n",
    "bias_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify-output/bias\"\n",
    "explainability_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify-output/explainability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 03\n",
    "\n",
    "tuning_job_name_prefix = \"xgbtune\" \n",
    "training_job_name_prefix = \"xgbtrain\"\n",
    "\n",
    "xgb_model_name = \"fraud-detect-xgb-model\"\n",
    "endpoint_name_prefix = \"xgb-fraud-model-dev\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.m4.xlarge\"\n",
    "clarify_instance_count = 1\n",
    "clarify_instance_type = \"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 04\n",
    "\n",
    "!mkdir -p tune-scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tune-scripts/xgboost_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tune-scripts/xgboost_train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Cell 05\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters and algorithm parameters are described here\n",
    "    parser.add_argument(\"--num_round\", type=int, default=100)\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=3)\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--colsample_bytree\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--objective\", type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument(\"--eval_metric\", type=str, default=\"auc\")\n",
    "    parser.add_argument(\"--nfold\", type=int, default=3)\n",
    "    parser.add_argument(\"--early_stopping_rounds\", type=int, default=3)\n",
    "    \n",
    "\n",
    "    # SageMaker specific arguments. Defaults are set in the environment variables\n",
    "    # Location of input training data\n",
    "    parser.add_argument(\"--train_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    # Location of input validation data\n",
    "    parser.add_argument(\"--validation_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    # Location where trained model will be stored. Default set by SageMaker, /opt/ml/model\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    # Location where model artifacts will be stored. Default set by SageMaker, /opt/ml/output/data\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    data_train = pd.read_csv(f\"{args.train_data_dir}/train.csv\")\n",
    "    train = data_train.drop(\"fraud\", axis=1)\n",
    "    label_train = pd.DataFrame(data_train[\"fraud\"])\n",
    "    dtrain = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    \n",
    "    data_validation = pd.read_csv(f\"{args.validation_data_dir}/validation.csv\")\n",
    "    validation = data_validation.drop(\"fraud\", axis=1)\n",
    "    label_validation = pd.DataFrame(data_validation[\"fraud\"])\n",
    "    dvalidation = xgb.DMatrix(validation, label=label_validation)\n",
    "\n",
    "    params = {\"max_depth\": args.max_depth,\n",
    "              \"eta\": args.eta,\n",
    "              \"objective\": args.objective,\n",
    "              \"subsample\" : args.subsample,\n",
    "              \"colsample_bytree\":args.colsample_bytree\n",
    "             }\n",
    "    \n",
    "    num_boost_round = args.num_round\n",
    "    nfold = args.nfold\n",
    "    early_stopping_rounds = args.early_stopping_rounds\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        metrics=[\"auc\"],\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=len(cv_results))\n",
    "    \n",
    "    train_pred = model.predict(dtrain)\n",
    "    validation_pred = model.predict(dvalidation)\n",
    "    \n",
    "    train_auc = roc_auc_score(label_train, train_pred)\n",
    "    validation_auc = roc_auc_score(label_validation, validation_pred)\n",
    "    \n",
    "    print(f\"[0]#011train-auc:{train_auc:.2f}\")\n",
    "    print(f\"[0]#011validation-auc:{validation_auc:.2f}\")\n",
    "\n",
    "    metrics_data = {\"hyperparameters\" : params,\n",
    "                    \"binary_classification_metrics\": {\"validation:auc\": {\"value\": validation_auc},\n",
    "                                                      \"train:auc\": {\"value\": train_auc}\n",
    "                                                     }\n",
    "                   }\n",
    "              \n",
    "    # Save the evaluation metrics to the location specified by output_data_dir\n",
    "    metrics_location = args.output_data_dir + \"/metrics.json\"\n",
    "    \n",
    "    # Save the model to the location specified by model_dir\n",
    "    model_location = args.model_dir + \"/xgboost-model\"\n",
    "\n",
    "    with open(metrics_location, \"w\") as f:\n",
    "        json.dump(metrics_data, f)\n",
    "\n",
    "    with open(model_location, \"wb\") as f:\n",
    "        joblib.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 06\n",
    "\n",
    "# SageMaker estimator\n",
    "\n",
    "# Set static hyperparameters that will not be tuned\n",
    "static_hyperparams = {  \n",
    "                        \"eval_metric\" : \"auc\",\n",
    "                        \"objective\": \"binary:logistic\",\n",
    "                        \"num_round\": \"5\"\n",
    "                      }\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"xgboost_train.py\",\n",
    "    source_dir=\"tune-scripts\",\n",
    "    output_path=estimator_output_uri,\n",
    "    code_location=estimator_output_uri,\n",
    "    hyperparameters=static_hyperparams,\n",
    "    role=sagemaker_role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    framework_version=\"1.3-1\",\n",
    "    base_job_name=training_job_name_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 07\n",
    "\n",
    "# Setting ranges of hyperparameters to be tuned\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"subsample\": ContinuousParameter(0.7, 0.95),\n",
    "    \"colsample_bytree\": ContinuousParameter(0.7, 0.95),\n",
    "    \"max_depth\": IntegerParameter(1, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 08\n",
    "\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "# Setting up tuner object\n",
    "tuner_config_dict = {\n",
    "                     \"estimator\" : xgb_estimator,\n",
    "                     \"max_jobs\" : 5,\n",
    "                     \"max_parallel_jobs\" : 2,\n",
    "                     \"objective_metric_name\" : objective_metric_name,\n",
    "                     \"hyperparameter_ranges\" : hyperparameter_ranges,\n",
    "                     \"base_tuning_job_name\" : tuning_job_name_prefix,\n",
    "                     \"strategy\" : \"Random\"\n",
    "                    }\n",
    "tuner = HyperparameterTuner(**tuner_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "#Cell 09\n",
    "\n",
    "# Setting the input channels for tuning job\n",
    "s3_input_train = TrainingInput(s3_data=\"s3://{}/{}\".format(read_bucket, train_data_key), content_type=\"csv\", s3_data_type=\"S3Prefix\")\n",
    "s3_input_validation = (\n",
    "    TrainingInput(s3_data=\"s3://{}/{}\".format(\n",
    "        read_bucket, validation_data_key), \n",
    "        content_type=\"csv\", s3_data_type=\"S3Prefix\"\n",
    "    )\n",
    ")\n",
    "\n",
    "tuner.fit(inputs={\"train\": s3_input_train, \"validation\": s3_input_validation}, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.817858</td>\n",
       "      <td>0.648688</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.807946</td>\n",
       "      <td>xgbtune-220822-1858-003-cc731205</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2022-08-22 19:02:34+00:00</td>\n",
       "      <td>2022-08-22 19:03:31+00:00</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.852787</td>\n",
       "      <td>0.084081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.829580</td>\n",
       "      <td>xgbtune-220822-1858-004-aa7b0c6d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2022-08-22 19:03:09+00:00</td>\n",
       "      <td>2022-08-22 19:04:14+00:00</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.883554</td>\n",
       "      <td>0.294907</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.888751</td>\n",
       "      <td>xgbtune-220822-1858-002-d70cb19a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2022-08-22 19:00:12+00:00</td>\n",
       "      <td>2022-08-22 19:02:25+00:00</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.711612</td>\n",
       "      <td>0.117673</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.730169</td>\n",
       "      <td>xgbtune-220822-1858-005-1678cc98</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2022-08-22 19:03:43+00:00</td>\n",
       "      <td>2022-08-22 19:04:40+00:00</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.733646</td>\n",
       "      <td>0.221355</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.753826</td>\n",
       "      <td>xgbtune-220822-1858-001-29d7c631</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2022-08-22 19:00:05+00:00</td>\n",
       "      <td>2022-08-22 19:02:17+00:00</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colsample_bytree       eta  max_depth  subsample  \\\n",
       "2          0.817858  0.648688        4.0   0.807946   \n",
       "1          0.852787  0.084081        2.0   0.829580   \n",
       "3          0.883554  0.294907        3.0   0.888751   \n",
       "0          0.711612  0.117673        3.0   0.730169   \n",
       "4          0.733646  0.221355        5.0   0.753826   \n",
       "\n",
       "                    TrainingJobName TrainingJobStatus  FinalObjectiveValue  \\\n",
       "2  xgbtune-220822-1858-003-cc731205         Completed                 0.79   \n",
       "1  xgbtune-220822-1858-004-aa7b0c6d         Completed                 0.70   \n",
       "3  xgbtune-220822-1858-002-d70cb19a         Completed                 0.70   \n",
       "0  xgbtune-220822-1858-005-1678cc98         Completed                 0.65   \n",
       "4  xgbtune-220822-1858-001-29d7c631         Completed                 0.63   \n",
       "\n",
       "          TrainingStartTime           TrainingEndTime  \\\n",
       "2 2022-08-22 19:02:34+00:00 2022-08-22 19:03:31+00:00   \n",
       "1 2022-08-22 19:03:09+00:00 2022-08-22 19:04:14+00:00   \n",
       "3 2022-08-22 19:00:12+00:00 2022-08-22 19:02:25+00:00   \n",
       "0 2022-08-22 19:03:43+00:00 2022-08-22 19:04:40+00:00   \n",
       "4 2022-08-22 19:00:05+00:00 2022-08-22 19:02:17+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "2                        57.0  \n",
       "1                        65.0  \n",
       "3                       133.0  \n",
       "0                        57.0  \n",
       "4                       132.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell 10\n",
    "\n",
    "# Summary of tuning results ordered in descending order of performance\n",
    "df_tuner = sagemaker.HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.job_name).dataframe()\n",
    "df_tuner = df_tuner[df_tuner[\"FinalObjectiveValue\"]>-float('inf')].sort_values(\"FinalObjectiveValue\", ascending=False)\n",
    "df_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 11\n",
    "\n",
    "tuner_job_info = sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)\n",
    "\n",
    "model_matches = sagemaker_client.list_models(NameContains=xgb_model_name)[\"Models\"]\n",
    "\n",
    "if not model_matches:\n",
    "    _ = sess.create_model_from_job(\n",
    "            name=xgb_model_name,\n",
    "            training_job_name=tuner_job_info['BestTrainingJob'][\"TrainingJobName\"],\n",
    "            role=sagemaker_role,\n",
    "            image_uri=tuner_job_info['TrainingJobDefinition'][\"AlgorithmSpecification\"][\"TrainingImage\"]\n",
    "            )\n",
    "else:\n",
    "\n",
    "    print(f\"Model {xgb_model_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  Clarify-Bias-2022-08-22-19-04-55-870\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-sample-files/datasets/tabular/synthetic_automobile_claims/train.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-622343165275/fraud-detect-demo/clarify-output/bias/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-622343165275/fraud-detect-demo/clarify-output/bias', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................................\u001b[34m2022-08-22 19:12:07,255 logging.conf not found when configuring logging, using default logging configuration.\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,256 Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,257 Analysis config path: /opt/ml/processing/input/config/analysis_config.json\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,257 Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,257 This host is algo-1.\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,257 This host is the leader.\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,257 Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,538 Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,538 Dataset type: text/csv uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,550 Loading dataset...\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/analyzer/data_loading/csv_data_loader.py:408: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_tmp, ignore_index=True)\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,579 Loaded dataset. Dataset info:\u001b[0m\n",
      "\u001b[34m<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mRangeIndex: 4009 entries, 0 to 4008\u001b[0m\n",
      "\u001b[34mData columns (total 48 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \u001b[0m\n",
      "\u001b[34m---  ------                           --------------  -----  \n",
      " 0   num_vehicles_involved            4009 non-null   int64  \n",
      " 1   num_injuries                     4009 non-null   int64  \n",
      " 2   num_witnesses                    4009 non-null   int64  \n",
      " 3   police_report_available          4009 non-null   int64  \n",
      " 4   injury_claim                     4009 non-null   int64  \n",
      " 5   vehicle_claim                    4009 non-null   float64\n",
      " 6   total_claim_amount               4009 non-null   float64\n",
      " 7   incident_month                   4009 non-null   int64  \n",
      " 8   incident_day                     4009 non-null   int64  \n",
      " 9   incident_dow                     4009 non-null   int64  \n",
      " 10  incident_hour                    4009 non-null   int64  \n",
      " 11  customer_age                     4009 non-null   int64  \n",
      " 12  months_as_customer               4009 non-null   int64  \n",
      " 13  num_claims_past_year             4009 non-null   int64  \n",
      " 14  num_insurers_past_5_years        4009 non-null   int64  \n",
      " 15  policy_deductable                4009 non-null   int64  \n",
      " 16  policy_annual_premium            4009 non-null   int64  \n",
      " 17  policy_liability                 4009 non-null   int64  \n",
      " 18  customer_education               4009 non-null   int64  \n",
      " 19  auto_year                        4009 non-null   int64  \n",
      " 20  driver_relationship_other        4009 non-null   int64  \n",
      " 21  driver_relationship_child        4009 non-null   int64  \n",
      " 22  driver_relationship_spouse       4009 non-null   int64  \n",
      " 23  driver_relationship_na           4009 non-null   int64  \n",
      " 24  driver_relationship_self         4009 non-null   int64  \n",
      " 25  incident_type_collision          4009 non-null   int64  \n",
      " 26  incident_type_break-in           4009 non-null   int64  \n",
      " 27  incident_type_theft              4009 non-null   int64  \n",
      " 28  collision_type_rear              4009 non-null   int64  \n",
      " 29  collision_type_side              4009 non-null   int64  \n",
      " 30  collision_type_na                4009 non-null   int64  \n",
      " 31  collision_type_front             4009 non-null   int64  \n",
      " 32  incident_severity_totaled        4009 non-null   int64  \n",
      " 33  incident_severity_major          4009 non-null   int64  \n",
      " 34  incident_severity_minor          4009 non-null   int64  \n",
      " 35  authorities_contacted_fire       4009 non-null   int64  \n",
      " 36  authorities_contacted_none       4009 non-null   int64  \n",
      " 37  authorities_contacted_police     4009 non-null   int64  \n",
      " 38  authorities_contacted_ambulance  4009 non-null   int64  \n",
      " 39  policy_state_ca                  4009 non-null   int64  \n",
      " 40  policy_state_az                  4009 non-null   int64  \n",
      " 41  policy_state_nv                  4009 non-null   int64  \n",
      " 42  policy_state_id                  4009 non-null   int64  \n",
      " 43  policy_state_wa                  4009 non-null   int64  \n",
      " 44  policy_state_or                  4009 non-null   int64  \n",
      " 45  customer_gender_other            4009 non-null   int64  \n",
      " 46  customer_gender_male             4009 non-null   int64  \n",
      " 47  customer_gender_female           4009 non-null   int64  \u001b[0m\n",
      "\u001b[34mdtypes: float64(2), int64(46)\u001b[0m\n",
      "\u001b[34mmemory usage: 1.5 MB\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,642 Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,642 Creating endpoint-config with name sm-clarify-config-1661195527-80c4\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:07,749 Creating endpoint: 'sm-clarify-fraud-detect-xgb-model-1661195527-e69c'\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:08,132 Using endpoint name: sm-clarify-fraud-detect-xgb-model-1661195527-e69c\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:08,133 Waiting for endpoint ...\u001b[0m\n",
      "\u001b[34m2022-08-22 19:12:08,133 Checking endpoint status:\u001b[0m\n",
      "\u001b[34mLegend:\u001b[0m\n",
      "\u001b[34m(OutOfService: x, Creating: -, Updating: -, InService: !, RollingBack: <, Deleting: o, Failed: *)\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:08,960 Endpoint is in service after 361 seconds\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:08,960 Endpoint ready.\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:08,960 ======================================\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:08,961 Calculating post-training bias metrics\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:08,961 ======================================\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:08,961 Getting predictions from the endpoint\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,653 We assume a prediction above 0.500 indicates 1 and below or equal indicates 0.\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,654 Column fraud with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,657 Column customer_gender_female with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py:456: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(facet_column.name, 1)\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,659 Column fraud with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,661 Column None with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,663 Stop using endpoint: sm-clarify-fraud-detect-xgb-model-1661195527-e69c\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,664 Deleting endpoint configuration with name: sm-clarify-config-1661195527-80c4\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,823 Deleting endpoint with name: sm-clarify-fraud-detect-xgb-model-1661195527-e69c\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,974 Model endpoint delivered 2.84410 requests per second and a total of 2 requests over 1 seconds\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,974 Stop using endpoint: None\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,974 =====================================\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,974 Calculating pre-training bias metrics\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,974 =====================================\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,975 Column fraud with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,977 Column customer_gender_female with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py:456: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(facet_column.name, 1)\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,979 Column fraud with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,981 ======================================\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,981 Calculating bias statistics for report\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,981 ======================================\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,982 Column fraud with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,983 Column customer_gender_female with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py:456: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(facet_column.name, 1)\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,985 Column fraud with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,987 Column None with data uniqueness fraction 0.0004988775255674732 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:09,990 Stop using endpoint: None\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:10,447 ['jupyter', 'nbconvert', \"-TagRemovePreprocessor.remove_input_tags='remove_input'\", '--to', 'html', '--output', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.ipynb', '--template', 'sagemaker-xai']\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 354224 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:11,713 ['/usr/local/bin/wkhtmltopdf', '-q', '--enable-local-file-access', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.pdf']\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:12,373 Collected analyses: \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"version\": \"1.0\",\n",
      "    \"post_training_bias_metrics\": {\n",
      "        \"label\": \"fraud\",\n",
      "        \"facets\": {\n",
      "            \"customer_gender_female\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"1\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"DPPL\",\n",
      "                            \"description\": \"Difference in Positive Proportions in Predicted Labels (DPPL)\",\n",
      "                            \"value\": -0.002210433244915988\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"0\"\n",
      "    },\n",
      "    \"pre_training_bias_metrics\": {\n",
      "        \"label\": \"fraud\",\n",
      "        \"facets\": {\n",
      "            \"customer_gender_female\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"1\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"CI\",\n",
      "                            \"description\": \"Class Imbalance (CI)\",\n",
      "                            \"value\": 0.12846096283362435\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"0\"\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-08-22 19:18:12,374 exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\u001b[34m-----!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cell 12\n",
    "\n",
    "train_df = pd.read_csv(train_data_uri)\n",
    "train_df_cols = train_df.columns.to_list()\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=clarify_instance_count,\n",
    "    instance_type=clarify_instance_type,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "# Data config\n",
    "bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_uri,\n",
    "    s3_output_path=bias_report_output_uri,\n",
    "    label=\"fraud\",\n",
    "    headers=train_df_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "# Model config\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=xgb_model_name,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "# Model predictions config to get binary labels from probabilities\n",
    "predictions_config = sagemaker.clarify.ModelPredictedLabelConfig(probability_threshold=0.5)\n",
    "\n",
    "# Bias config\n",
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name=\"customer_gender_female\",\n",
    "    facet_values_or_threshold=[1],\n",
    ")\n",
    "\n",
    "# Run Clarify job\n",
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=[\"CI\"],\n",
    "    post_training_methods=[\"DPPL\"])\n",
    "\n",
    "clarify_bias_job_name = clarify_processor.latest_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  Clarify-Bias-2022-08-22-19-18-52-052\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-sample-files/datasets/tabular/synthetic_automobile_claims/train.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-622343165275/fraud-detect-demo/clarify-output/bias/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-622343165275/fraud-detect-demo/clarify-output/bias', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............................."
     ]
    }
   ],
   "source": [
    "#Cell 13\n",
    "\n",
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=[\"CI\"],\n",
    "    post_training_methods=[\"DPPL\"]\n",
    "    )\n",
    "\n",
    "clarify_bias_job_name = clarify_processor.latest_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 14\n",
    "\n",
    "# Copy bias report and view locally\n",
    "!aws s3 cp s3://{write_bucket}/{write_prefix}/clarify-output/bias/report.pdf ./clarify_bias_output.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 15\n",
    "\n",
    "explainability_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_uri,\n",
    "    s3_output_path=explainability_report_output_uri,\n",
    "    label=\"fraud\",\n",
    "    headers=train_df_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "# Use mean of train dataset as baseline data point\n",
    "shap_baseline = [list(train_df.drop([\"fraud\"], axis=1).mean())]\n",
    "\n",
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=shap_baseline,\n",
    "    num_samples=500,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=True,\n",
    ")\n",
    "\n",
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 16\n",
    "\n",
    "# Copy explainability report and view\n",
    "!aws s3 cp s3://{write_bucket}/{write_prefix}/clarify-output/explainability/report.pdf ./clarify_explainability_output.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 17\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "local_explanations_out = pd.read_csv(explainability_report_output_uri + \"/explanations_shap/out.csv\")\n",
    "feature_names = [str.replace(c, \"_label0\", \"\") for c in \n",
    "local_explanations_out.columns.to_series()]\n",
    "local_explanations_out.columns = feature_names\n",
    "\n",
    "selected_example = 100\n",
    "print(\"Example number:\", selected_example)\n",
    "\n",
    "local_explanations_out.iloc[selected_example].plot(\n",
    "    kind=\"bar\", title=\"Local explanation for the example number \" + str(selected_example), rot=60, figsize=(20, 8)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 18\n",
    "\n",
    "best_train_job_name = tuner.best_training_job()\n",
    "\n",
    "model_path = estimator_output_uri + '/' + best_train_job_name + '/output/model.tar.gz'\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "create_model_config = {\"model_data\":model_path,\n",
    "                       \"role\":sagemaker_role,\n",
    "                       \"image_uri\":training_image,\n",
    "                       \"name\":endpoint_name_prefix,\n",
    "                       \"predictor_cls\":sagemaker.predictor.Predictor\n",
    "                       }\n",
    "# Create a SageMaker model\n",
    "model = sagemaker.model.Model(**create_model_config)\n",
    "\n",
    "# Deploy the best model and get access to a SageMaker Predictor\n",
    "predictor = model.deploy(initial_instance_count=predictor_instance_count, \n",
    "                         instance_type=predictor_instance_type,\n",
    "                         serializer=CSVSerializer(),\n",
    "                         deserializer=CSVDeserializer())\n",
    "print(f\"\\nModel deployed at endpoint : {model.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 19\n",
    "\n",
    "# Sample test data\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "payload = test_df.drop([\"fraud\"], axis=1).iloc[0].to_list()\n",
    "print(f\"Model predicted score : {float(predictor.predict(payload)[0][0]):.3f}, True label : {test_df['fraud'].iloc[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "try:\n",
    "\tsess.delete_model(xgb_model_name)\n",
    "except:\n",
    "\tpass\n",
    "sess.delete_model(model.name)\n",
    "\n",
    "# Delete inference endpoint config\n",
    "sess.delete_endpoint_config(endpoint_config_name=predictor._get_endpoint_config_name())\n",
    "\n",
    "# Delete inference endpoint\n",
    "sess.delete_endpoint(endpoint_name=model.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
