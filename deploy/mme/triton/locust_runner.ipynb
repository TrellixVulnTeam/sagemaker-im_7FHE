{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520ff30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "region = 'us-east-1'\n",
    "content_type = 'text/csv'\n",
    "endpoint_name='sagemaker-decision-trees-2021-03-17-03-32-20-604'\n",
    "\n",
    "boto3config = Config(\n",
    "    retries={\n",
    "        'max_attempts': 100,\n",
    "        'mode': 'standard'\n",
    "    }\n",
    ")\n",
    "\n",
    "payload='5.0,3.5,1.3,0.3\\n'\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker-runtime',\n",
    "                                     config=boto3config,\n",
    "                                     region_name=region)\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=content_type\n",
    ")\n",
    "response_body = response[\"Body\"].read()\n",
    "\n",
    "response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33034b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_mask = []\n",
    "import json\n",
    "\n",
    "# open file in write mode\n",
    "with open(r'../../temp-bloom/input_ids.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        # remove linebreak from a current name\n",
    "        # linebreak is the last character of each line\n",
    "        x = line[:-1]\n",
    "\n",
    "        # add current item to the list\n",
    "        input_ids.append(int(x))\n",
    "    print(f\"Done input_ids size={len(input_ids)}::\")\n",
    "    \n",
    "# open file in write mode\n",
    "with open(r'../../temp-bloom/attention_mask.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        # remove linebreak from a current name\n",
    "        # linebreak is the last character of each line\n",
    "        x = line[:-1]\n",
    "\n",
    "        # add current item to the list\n",
    "        attention_mask.append(int(x))\n",
    "    print(f\"Done attention_mask size={len(attention_mask)}::\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1734e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length=512\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('./payload_json.json', 'w') as fp:\n",
    "    json.dump(payload, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ca3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_read = None\n",
    "with open('./payload_json.json', 'r') as fp:\n",
    "    payload_read = json.load(fp)\n",
    "payload_read.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb75077",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "region = 'us-east-1'\n",
    "content_type = 'text/csv'\n",
    "endpoint_name_p5='p5-bert-uc--2022-09-08-03-02-53-774'\n",
    "\n",
    "boto3config = Config(\n",
    "    retries={\n",
    "        'max_attempts': 100,\n",
    "        'mode': 'standard'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker-runtime',\n",
    "                                     config=boto3config,\n",
    "                                     region_name=region)\n",
    "\n",
    "max_seq_length=512\n",
    "print(f\"Leverage the stored:ids: max_seq_length={max_seq_length}:: create above when creating the model : INPUTSid's and attention masks read earlier\")\n",
    "#input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5, ContentType=\"application/octet-stream\", Body=json.dumps(payload), \n",
    ")\n",
    "\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "print(output_dict.keys())\n",
    "\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5, ContentType=\"text/json\", Body=json.dumps(payload)\n",
    ")\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "print(output_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict['outputs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224d272",
   "metadata": {},
   "source": [
    "**RUN Locust for end piont can be MME or normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_start = datetime.datetime.utcnow()\n",
    "!/home/ec2-user/anaconda3/envs/python3/bin/locust -f locust_script.py -u 50 --headless --host=http://$endpoint_name_p5 --stop-timeout 90 -L DEBUG -t 5m --logfile=logfile.log --csv=payload_json.json --csv-full-history --reset-stats              \n",
    "cw_end = datetime.datetime.utcnow()        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab60491",
   "metadata": {},
   "source": [
    "**RUN MME Now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "region = 'us-east-1'\n",
    "content_type = 'text/csv'\n",
    "endpoint_name_p5_mme = 'p5-bert-uc-mme-2022-09-08-19-55-35-829'\n",
    "\n",
    "boto3config = Config(\n",
    "    retries={\n",
    "        'max_attempts': 100,\n",
    "        'mode': 'standard'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker-runtime',\n",
    "                                     config=boto3config,\n",
    "                                     region_name=region)\n",
    "\n",
    "max_seq_length=512\n",
    "print(f\"Leverage the stored:ids: max_seq_length={max_seq_length}:: create above when creating the model : INPUTSid's and attention masks read earlier\")\n",
    "#input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5_mme, ContentType=\"application/octet-stream\", Body=json.dumps(payload), TargetModel  = \"/model-9/model.tar.gz\"\n",
    ")\n",
    "\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "print(output_dict.keys())\n",
    "\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5, ContentType=\"text/json\", Body=json.dumps(payload)\n",
    ")\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "print(output_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0563c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict['outputs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0627a9",
   "metadata": {},
   "source": [
    "### Previous Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a05279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cw_start = datetime.datetime.utcnow()\n",
    "!/home/ec2-user/anaconda3/envs/python3/bin/locust -f locust_script.py -u 50 --headless --host=http://sagemaker-decision-trees-2021-03-17-03-32-20-604 --stop-timeout 90 -L DEBUG -t 5m --logfile=logfile.log --csv=locust.csv --csv-full-history --reset-stats              \n",
    "cw_end = datetime.datetime.utcnow()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e25877",
   "metadata": {},
   "outputs": [],
   "source": [
    "locust_data = pd.read_csv('locust.csv_stats.csv')\n",
    "for index, row in locust_data.head(n=2).iterrows():\n",
    "     print(index, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bce8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "statistics = ['Sum', 'SampleCount', 'Average', 'Minimum', 'Maximum']\n",
    "extended = ['p50', 'p90', 'p95', 'p99', 'p100']\n",
    "\n",
    "metrics_to_gather = []\n",
    "metrics_to_gather.append('CPUUtilization')\n",
    "metrics_to_gather.append('MemoryUtilization')\n",
    "metrics_to_gather.append('GPUUtilization')\n",
    "metrics_to_gather.append('GPUMemoryUtilization')\n",
    "metrics_to_gather.append('DiskUtilization')\n",
    "metrics_to_gather.append('ModelLatency')\n",
    "metrics_to_gather.append('OverheadLatency')\n",
    "metrics_to_gather.append('Invocations')\n",
    "metrics_to_gather.append('Invocation4XXErrors')\n",
    "metrics_to_gather.append('Invocation5XXErrors')\n",
    "metrics_to_gather.append('InvocationsPerInstance')\n",
    "#metrics_to_gather.append('ModelLoadingTime')\n",
    "#metrics_to_gather.append('ModelCacheHit')\n",
    "#metrics_to_gather.append('ModelDownloadingTime')\n",
    "#metrics_to_gather.append('ModelLoadingWaitTime')\n",
    "#metrics_to_gather.append('ModelUnloadingTime')\n",
    "#metrics_to_gather.append('LoadedModelCount')\n",
    "\n",
    "def get_sample_count(cw_end, cw_start):\n",
    "    \n",
    "    cloudwatch = boto3.client('cloudwatch')\n",
    "    metrics_to_gather=['Invocations']\n",
    "    statistics=['SampleCount']\n",
    "    \n",
    "    # Period must be 1, 5, 10, 30, or multiple of 60\n",
    "    # Calculate closest multiple of 60 to the total elapsed time\n",
    "    factor = math.ceil((cw_end - cw_start).total_seconds() / 60)\n",
    "    period = factor * 60\n",
    "    \n",
    "    cloudwatch_ready = False\n",
    "    \n",
    "    # Keep polling CloudWatch metrics until datapoints are available\n",
    "    while not cloudwatch_ready:\n",
    "        time.sleep(90)\n",
    "        for metric in metrics_to_gather:\n",
    "            model_latency_metrics = cloudwatch.get_metric_statistics(MetricName=metric,\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': endpoint_name_p5},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=\"AWS/SageMaker\",\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics\n",
    "                                             )\n",
    "            #print(metric)\n",
    "            if len(model_latency_metrics['Datapoints']) > 0:\n",
    "                samplecount = model_latency_metrics['Datapoints'][0]['SampleCount']\n",
    "                cloudwatch_ready = True\n",
    "    \n",
    "    return(samplecount)\n",
    "\n",
    "def collect_cloudwatch_metrics(statistics, extended, metrics_to_gather, total_runs, cw_end, cw_start):\n",
    "    \n",
    "    print('Getting Cloudwatch:')\n",
    "    cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "    # Period must be 1, 5, 10, 30, or multiple of 60\n",
    "    # Calculate closest multiple of 60 to the total elapsed time\n",
    "    factor = math.ceil((cw_end - cw_start).total_seconds() / 60)\n",
    "    period = factor * 60\n",
    "    print('Time elapsed: {} seconds'.format((cw_end - cw_start).total_seconds()))\n",
    "    print('Using period of {} seconds\\n'.format(period))\n",
    "\n",
    "    cloudwatch_ready = False\n",
    "    \n",
    "    # Keep polling CloudWatch metrics until datapoints are available\n",
    "    while not cloudwatch_ready:\n",
    "        \n",
    "        time.sleep(90)\n",
    "        \n",
    "        print('Waiting 30 seconds ...')\n",
    "\n",
    "        for metric in metrics_to_gather:\n",
    "            \n",
    "            if(metric.find('Util') != -1):\n",
    "                namespace = \"/aws/sagemaker/Endpoints\"\n",
    "            else:\n",
    "                namespace = \"AWS/SageMaker\"\n",
    "            \n",
    "            model_latency_metrics = cloudwatch.get_metric_statistics(MetricName=metric,\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': endpoint_name_p5_mme},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=namespace,\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics,\n",
    "                                             ExtendedStatistics=extended\n",
    "                                             )            \n",
    "            #print(metric)\n",
    "            if len(model_latency_metrics['Datapoints']) > 0:\n",
    "                #print(model_latency_metrics)\n",
    "                print(metric +'\\n')\n",
    "                side_avg = model_latency_metrics['Datapoints'][0]['Average'] / total_runs\n",
    "                side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50'] / total_runs\n",
    "                side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90'] / total_runs\n",
    "                side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95'] / total_runs\n",
    "                side_p99 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p99'] / total_runs\n",
    "                side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100'] / total_runs\n",
    "\n",
    "                sumcount = model_latency_metrics['Datapoints'][0]['Sum']\n",
    "                samplecount = model_latency_metrics['Datapoints'][0]['SampleCount']\n",
    "                average = model_latency_metrics['Datapoints'][0]['Average']\n",
    "                minimum = model_latency_metrics['Datapoints'][0]['Minimum']\n",
    "                maximum = model_latency_metrics['Datapoints'][0]['Maximum']\n",
    "\n",
    "                #statistics = ['Sum', 'SampleCount', 'Average', 'Minimum', 'Maximum']\n",
    "                #extended = ['p50', 'p90', 'p95', 'p99', 'p100']\n",
    "                print('Avg | P50 | P90 | P95 | P95 | P100')\n",
    "                print('{:.4f} | {:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(side_avg, side_p50, side_p90, side_p95, side_p99, side_p100))\n",
    "                print('Sum | SampleCount | Average | Minimum | Maximum')\n",
    "                print('{:.4f} | {:.4f} | {:.4f} | {:.4f} | {:.4f}\\n'.format(sumcount, samplecount, average, minimum, maximum))\n",
    "                \n",
    "                cloudwatch_ready = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs = get_sample_count(cw_end, cw_start)\n",
    "collect_cloudwatch_metrics(statistics, extended, metrics_to_gather, total_runs, cw_end, cw_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5aa7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
