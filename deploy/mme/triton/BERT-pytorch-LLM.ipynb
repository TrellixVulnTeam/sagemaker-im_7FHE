{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97228777",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    'us-east-1': '785573368785',\n",
    "    'us-east-2': '007439368137',\n",
    "    'us-west-1': '710691900526',\n",
    "    'us-west-2': '301217895009',\n",
    "    'eu-west-1': '802834080501',\n",
    "    'eu-west-2': '205493899709',\n",
    "    'eu-west-3': '254080097072',\n",
    "    'eu-north-1': '601324751636',\n",
    "    'eu-south-1': '966458181534',\n",
    "    'eu-central-1': '746233611703',\n",
    "    'ap-east-1': '110948597952',\n",
    "    'ap-south-1': '763008648453',\n",
    "    'ap-northeast-1': '941853720454',\n",
    "    'ap-northeast-2': '151534178276',\n",
    "    'ap-southeast-1': '324986816169',\n",
    "    'ap-southeast-2': '355873309152',\n",
    "    'cn-northwest-1': '474822919863',\n",
    "    'cn-north-1': '472730292857',\n",
    "    'sa-east-1': '756306329178',\n",
    "    'ca-central-1': '464438896020',\n",
    "    'me-south-1': '836785723513',\n",
    "    'af-south-1': '774647643957'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272d96ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.9.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (2021.11.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (1.21.2)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (4.62.3)\n",
      "Requirement already satisfied: torch!=0.12.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers[torch]) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging>=20.0->transformers[torch]) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44bf219",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting nvidia-pyindex\n",
      "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-pyindex\n",
      "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8413 sha256=03d4e5f8b678c8e0714d13efba42d37b3c32e94b7bdefdbcf6d41ea087df0add\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e0/c2/fb/5cf4e1cfaf28007238362cb746fb38fc2dd76348331a748d54\n",
      "Successfully built nvidia-pyindex\n",
      "Installing collected packages: nvidia-pyindex\n",
      "Successfully installed nvidia-pyindex-1.0.9\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting tritonclient[http]\n",
      "  Downloading tritonclient-2.25.0-py3-none-manylinux1_x86_64.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m341.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-rapidjson>=0.9.1\n",
      "  Downloading python_rapidjson-1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m386.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tritonclient[http]) (1.21.2)\n",
      "Collecting geventhttpclient>=1.4.4\n",
      "  Downloading geventhttpclient-2.0.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 KB\u001b[0m \u001b[31m289.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp>=3.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tritonclient[http]) (3.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (2.0.7)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (4.0.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (2021.10.8)\n",
      "Requirement already satisfied: gevent>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (21.8.0)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m353.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp>=3.8.1->tritonclient[http]) (4.0.0)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (59.2.0)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (4.5.0)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (5.4.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.1->tritonclient[http]) (3.1)\n",
      "Installing collected packages: brotli, python-rapidjson, tritonclient, geventhttpclient\n",
      "Successfully installed brotli-1.0.9 geventhttpclient-2.0.2 python-rapidjson-1.8 tritonclient-2.25.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.73 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-pyindex\n",
    "!pip install tritonclient[http]\n",
    "\n",
    "!pip install -qU pip awscli boto3 sagemaker transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb9823",
   "metadata": {},
   "source": [
    "### Test Create BERT model from HuggingFace\n",
    "**If you use from BERT it comes without HEAD o you need to add Head or alternately download from HuggingFace or using Auto so you get with Head**\n",
    "\n",
    "**Test how to create BERT torchscript model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8feac6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894c3c4ea71c438ebcc34290d2ffe1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c483ff841844fda3516351bead9bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1ce0ab6f404bcb8adb98605f8c33d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7b8dc51c5f46e297ec39f9e69880cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT:Tokenized:Text=['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']:::\n",
      "BERT:indexed_tokens:=[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 13997, 11510, 102]::\n",
      "BERT:Combining:DICT: all: creating dummy:input:Model:={'input_ids': tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])}::\n",
      "BERT:Finally combining all: creating dummy:input=[tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])]::\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cef8a64e26d499ea71381a471aa9d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "print(f\"BERT:Tokenized:Text={tokenized_text}:::\")\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "print(f\"BERT:indexed_tokens:={indexed_tokens}::\")\n",
    "\n",
    "# -- segments id's\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "dummy_model_input = {'input_ids':tokens_tensor, 'attention_mask':segments_tensors }\n",
    "print(f\"BERT:Combining:DICT: all: creating dummy:input:Model:={dummy_model_input}::\")\n",
    "\n",
    "dummy_input = [tokens_tensor, segments_tensors]\n",
    "print(f\"BERT:Finally combining all: creating dummy:input={dummy_input}::\")\n",
    "\n",
    "# Initializing the model with the torchscript flag\n",
    "# Flag set to True even though it is not necessary as this model does not have an LM Head.\n",
    "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, torchscript=True)\n",
    "\n",
    "# Instantiating the model\n",
    "model = BertModel(config)\n",
    "\n",
    "# The model needs to be in evaluation mode for torchscript \n",
    "model.eval()\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "\n",
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n",
    "#torch.jit.save(traced_model, \"./bert-uc/traced_bert.pt\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec14d7d8",
   "metadata": {},
   "source": [
    "for quantized export of the model to reduce size\n",
    "\n",
    "python convert_graph_to_onnx.py --framework <pt, tf> --model bert-base-cased --quantize bert-base-cased.onnx\n",
    "\n",
    "from transformers import converst_graph_to_onnx\n",
    "!python convert_graph_to_onnx.py --framework pt --model ./bert-uc/traced_bert.pt --quantize bert-base-uncased.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33776f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BERT Tokensizer::\n",
      "[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 13997, 11510, 102]\n",
      "[tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])]\n",
      "{'input_ids': tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Using the BERT Tokensizer::\")\n",
    "\n",
    "print(indexed_tokens)\n",
    "print(dummy_input)\n",
    "print(dummy_model_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58b811",
   "metadata": {},
   "source": [
    "dummy_model_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964d20d",
   "metadata": {},
   "source": [
    "**Test Tokenizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991fceac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71592a155ca34f5cb792b1dac7f2bff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f669416795545678c858f3edec744a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55483c5286424f92a037ea818296e0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f6adbf31e64cf098e66279eb3a1571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BERT:AUTO:TOKENSIZER: Tokenizer::\n",
      "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# load model and tokenizer\n",
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "dummy_model_bert_input = tokenizer(\"This is a sample\", return_tensors=\"pt\")\n",
    "\n",
    "print(\"Using the BERT:AUTO:TOKENSIZER: Tokenizer::\")\n",
    "print(dummy_model_bert_input) # -- dict -- input id's and attention mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd85f0",
   "metadata": {},
   "source": [
    "### Export as ONYX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9160ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:219: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# export\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    tuple(dummy_model_input.values()), #tuple(dummy_model_input.values()),\n",
    "    f=\"./bert-uc/torch-model.onnx\",  \n",
    "    input_names=['input_ids', 'attention_mask'], \n",
    "    output_names=['logits'], \n",
    "    dynamic_axes={'input_ids': {0: 'batch_size', 1: 'sequence'}, \n",
    "                  'attention_mask': {0: 'batch_size', 1: 'sequence'}, \n",
    "                  'logits': {0: 'batch_size', 1: 'sequence'}}, \n",
    "    do_constant_folding=True, \n",
    "    opset_version=13, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokens_tensor, segments_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07edfec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "269901de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 <class 'tuple'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "\n",
    "# Change to eva lmodel\n",
    "model.eval()\n",
    "\n",
    "# run a dummy prediction of tokens by tensors\n",
    "output = model(tokens_tensor)\n",
    "print(len(output), type(output), type(output[0]))\n",
    "\n",
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n",
    "#torch.jit.save(traced_model, \"./triton-serve/bert-uc/1/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e02b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT:Tokenized:Text=['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']:::\n",
      "BERT:indexed_tokens:=[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 13997, 11510, 102]::\n",
      "tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "print(f\"BERT:Tokenized:Text={tokenized_text}:::\")\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "print(f\"BERT:indexed_tokens:={indexed_tokens}::\")\n",
    "\n",
    "# -- segments id's -- CAN WE GENERATE THEM via model\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "print(tokens_tensor)\n",
    "print(segments_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636a86a",
   "metadata": {},
   "source": [
    "## Start actual BERT with Head for Triton\n",
    "\n",
    "### This model from HuggingFace does not take the attension ID's so accepts only 1 input\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  },\n",
    "  \n",
    "  \n",
    "    {\n",
    "    name: \"INPUT__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  }\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fdda5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting triton-serve/bert-uc/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile triton-serve/bert-uc/config.pbtxt\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 32\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  },\n",
    "  {\n",
    "    name: \"INPUT__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [512, 768]\n",
    "  },\n",
    "  {\n",
    "    name: \"1634__1\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [768]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}\n",
    "dynamic_batching {\n",
    "  preferred_batch_size: 32\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef0dbb",
   "metadata": {},
   "source": [
    "### Run for Triton server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd855d2",
   "metadata": {},
   "source": [
    "**Note**: Amazon SageMaker expects the model tarball file to have a top level directory with the same name as the model defined in the `config.pbtxt`. Below is the sample model directory structure\n",
    "\n",
    "```\n",
    "bert-uc\n",
    "├── 1\n",
    "│   └── model.pt\n",
    "└── config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "115a8bdb",
   "metadata": {},
   "source": [
    "tar --exclude=\".git\" --exclude=\".gitattributes\" --exclude=\"model.tar.gz\" --exclude=\"*.bin\" -zcvf model.tar.gz bert-uc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e435025",
   "metadata": {},
   "source": [
    "**Have to use the same Tokenizer to generate the input to test as BERT uncased**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d364fc",
   "metadata": {},
   "source": [
    "### Create the BERT Model in Torch Script mode -- .pt model\n",
    "use the ore trained and use torchscript flag here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc9564",
   "metadata": {},
   "source": [
    "### Create the LARGE CASE BERT Model in Torch Script using dummy inputs -- .pt model\n",
    "Create using the dummy inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75612732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPTJModel\n",
    "from transformers import GPTJForCausalLM, AutoTokenizer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80873336",
   "metadata": {},
   "source": [
    "### Run a simple test for BERT LARGE uncased \n",
    "\n",
    "    * We run multiple tests\n",
    "        * First we token ize and then de tokenize to make sure the vaues match\n",
    "        * Then we use the model and run predictions to get values\n",
    "        * Then we run on the traced Model and run predictions to get values \n",
    "        * Check to make sure they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d02d6af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4472,  0.3378, -0.1825,  ..., -0.8584, -1.3538,  0.4175],\n",
       "         [-0.2535,  0.1439, -0.1481,  ..., -0.5559, -0.3288, -0.1320],\n",
       "         [-0.1767, -0.2466, -0.3732,  ..., -0.2728,  0.2910,  0.3882],\n",
       "         ...,\n",
       "         [-0.0674, -0.3769,  0.0228,  ...,  0.1540,  0.8440,  0.2331],\n",
       "         [ 0.0884,  0.4401, -0.8590,  ..., -0.2341, -1.5650, -0.2771],\n",
       "         [-0.3043,  0.1687, -0.3263,  ..., -0.2537,  0.0570,  0.5401]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9507, -0.9791,  0.9999,  ..., -0.9996,  0.8956, -0.9869]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', torchscript=True)\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "text = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\" #\"Replace me by any text you'd like.\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "output = model(**encoded_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09bd5998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs['input_ids'], dummy_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1f3d8f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2316: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BertModel(\n",
      "  original_name=BertModel\n",
      "  (embeddings): BertEmbeddings(\n",
      "    original_name=BertEmbeddings\n",
      "    (word_embeddings): Embedding(original_name=Embedding)\n",
      "    (position_embeddings): Embedding(original_name=Embedding)\n",
      "    (token_type_embeddings): Embedding(original_name=Embedding)\n",
      "    (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "    (dropout): Dropout(original_name=Dropout)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    original_name=BertEncoder\n",
      "    (layer): ModuleList(\n",
      "      original_name=ModuleList\n",
      "      (0): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (12): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (13): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (14): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (15): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (16): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (17): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (18): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (19): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (20): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (21): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (22): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (23): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    original_name=BertPooler\n",
      "    (dense): Linear(original_name=Linear)\n",
      "    (activation): Tanh(original_name=Tanh)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# -- IF you use from bert it comes without HEAD \n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\", torchscript=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "\n",
    "bs = 1\n",
    "seq_len = 512\n",
    "dummy_inputs = [\n",
    "    torch.randint(1000, (bs, seq_len)).to(device),\n",
    "    torch.zeros(bs, seq_len, dtype=torch.int).to(device),\n",
    "]\n",
    "traced_model = torch.jit.trace(model, dummy_inputs)\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "dummy_inputs = tokenizer(text, return_tensors='pt', max_length=seq_len, padding=True)\n",
    "traced_model = torch.jit.trace(model, dummy_inputs)\n",
    "\n",
    "model = model.eval()\n",
    "# model.to(device)\n",
    "torch.jit.save(traced_model, \"./triton-serve/bert-uc/1/model.pt\")\n",
    "\n",
    "print(\"Saved {}\".format(traced_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32a928ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da89bf",
   "metadata": {},
   "source": [
    "#### Test encoders various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c4f732c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 13012, 2669, 28937, 8241, 3640, 1037, 6112, 1998, 3341, 1999, 7512, 2368, 6129, 5576, 23569, 27605, 5422, 2005, 2119, 17368, 2015, 1998, 14246, 2271, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\", \n",
    "    padding=\"max_length\", \n",
    "    max_length=64\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2c445bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode_plus(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\",\n",
    "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length = 512,           \n",
    "    pad_to_max_length = True, # Pad & truncate all sentences\n",
    ")\n",
    "#encoded_tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e002220",
   "metadata": {},
   "source": [
    "**Predict test using the traced model Needs Tokens and Attention mask both**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ba0e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tokens['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f25ab7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'triton inference server provides a cloud and edge inferencing solution optimized for both cpus and gpus.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(\n",
    "    encoded_tokens['input_ids'],\n",
    "    skip_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "#     max_length = 512,           \n",
    "#     pad_to_max_length = True, # Pad & truncate all sentences\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de61b649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  101, 13012,  2669, 28937,  8241,  3640,  1037,  6112,  1998,  3341,\n",
       "           1999,  7512,  2368,  6129,  5576, 23569, 27605,  5422,  2005,  2119,\n",
       "          17368,  2015,  1998, 14246,  2271,  1012,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[encoded_input['input_ids'],encoded_input['attention_mask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "111013e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4472,  0.3378, -0.1825,  ..., -0.8584, -1.3538,  0.4175],\n",
       "         [-0.2535,  0.1439, -0.1481,  ..., -0.5559, -0.3288, -0.1320],\n",
       "         [-0.1767, -0.2466, -0.3732,  ..., -0.2728,  0.2910,  0.3882],\n",
       "         ...,\n",
       "         [ 0.0150,  0.6082,  0.0717,  ...,  0.3446, -0.2089, -0.2529],\n",
       "         [ 0.0930,  0.2063, -0.1411,  ..., -0.3262, -0.6821, -0.1691],\n",
       "         [ 0.0200,  0.7166,  0.0530,  ...,  0.1955, -0.1783, -0.2524]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9507, -0.9791,  0.9999,  ..., -0.9996,  0.8956, -0.9869]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\", \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length = 100, # -- this model has max length set to 100 -- not to 512,           \n",
    "    pad_to_max_length = True, # Pad & truncate all sentences\n",
    "\n",
    ")\n",
    "#unscripted_output = model.generate( # -- This is for GPTJ version of the model and so uses do_sample, temperature etc \n",
    "unscripted_output = model( # -- both work the same way \n",
    "    **encoded_input, \n",
    "    #inputs=encoded_input['attention_mask']],\n",
    "    return_dict=True, \n",
    "    output_attentions=False, \n",
    "    output_hidden_states=False,\n",
    "\n",
    "    #do_sample=True,\n",
    "    #temperature=0.9,\n",
    "    #max_length=128,\n",
    ")\n",
    "\n",
    "#tokenizer.decode(unscripted_output[0])\n",
    "unscripted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79a81158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4472,  0.3378, -0.1825,  ..., -0.8584, -1.3538,  0.4175],\n",
       "          [-0.2535,  0.1439, -0.1481,  ..., -0.5559, -0.3288, -0.1320],\n",
       "          [-0.1767, -0.2466, -0.3732,  ..., -0.2728,  0.2910,  0.3882],\n",
       "          ...,\n",
       "          [ 0.0150,  0.6082,  0.0717,  ...,  0.3446, -0.2089, -0.2529],\n",
       "          [ 0.0930,  0.2063, -0.1411,  ..., -0.3262, -0.6821, -0.1691],\n",
       "          [ 0.0200,  0.7166,  0.0530,  ...,  0.1955, -0.1783, -0.2524]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[-0.9507, -0.9791,  0.9999,  ..., -0.9996,  0.8956, -0.9869]],\n",
       "        grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\", \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length = 100, # -- this model has max length set to 100 -- not to 512,           \n",
    "    pad_to_max_length = True, # Pad & truncate all sentences\n",
    "\n",
    ")\n",
    "# Traced Model expects ONLY the INPUT ID's\n",
    "unscripted_traced_output = traced_model( # -- both work the same way \n",
    "    encoded_input['input_ids'] , encoded_input['attention_mask']\n",
    ")\n",
    "\n",
    "#tokenizer.decode(unscripted_output[0])\n",
    "unscripted_traced_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f3a1bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9045, -0.9739,  0.9999,  ..., -0.9985,  0.8936, -0.9707]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscripted_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1df34050",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.batch_decode(unscripted_output[1])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0e14a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 13012,  2669, 28937,  8241,  3640,  1037,  6112,  1998,  3341,\n",
       "          1999,  7512,  2368,  6129,  5576, 23569, 27605,  5422,  2005,  2119,\n",
       "         17368,  2015,  1998, 14246,  2271,  1012,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "         19101, 26256, 17884,   524, 21002,  7116, 29986, 25690, 24989, 11437,\n",
       "         25153, 18364, 20228,  8929, 12011, 16143, 15691, 25636, 13067,  9410,\n",
       "          1842, 11753,  1594, 18910, 12128, 20549,  6186, 24852]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscripted_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea157fa2",
   "metadata": {},
   "source": [
    "### Use the single input to create the traced model in case the model accepts 1 inputs \n",
    "### In case Model accepts 2 inputs like BERT then use 2 to create Traced scripting model\n",
    "**torch.save(model, \"./triton-serve/bert-uc/1/model.pt\") Does not work**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f72a4",
   "metadata": {},
   "source": [
    "### UPLOAD of the Model.tar after it has been created correctly by \n",
    "\n",
    "Because we share the same model tar with bloom and with bert-uc\n",
    "rm model.tar.gz in the triton-serve directory\n",
    "\n",
    "\n",
    "tar --exclude=\".git\" --exclude=\".gitattributes\" --exclude=\"model.tar.gz\" --exclude=\"*.bin\" --exclude \"*.tar\" -zcvf model.tar.gz bert-uc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9794c26",
   "metadata": {},
   "source": [
    "**Upload the model.tar.gz to S3 location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "745a145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b7cb2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc/model.tar.gz\n",
      "s3://sagemaker-us-east-1-622343165275/bloom/triton_models/\n"
     ]
    }
   ],
   "source": [
    "s3_model_path_triton = sagemaker.s3.S3Uploader().upload(\n",
    "    local_path=\"./triton-serve/model.tar.gz\",\n",
    "    desired_s3_uri=\"s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc\",\n",
    "    sagemaker_session=session\n",
    ")\n",
    "s3_mme_model_path='s3://sagemaker-us-east-1-622343165275/bloom/triton_models/'\n",
    "print(s3_model_path_triton)\n",
    "print(s3_mme_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c0a51",
   "metadata": {},
   "source": [
    "#### Start Single Model Triton for starting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29da70",
   "metadata": {},
   "source": [
    "**Triton Image download and sagemaker variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "770f8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tritonserver:22.07-py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "import boto3\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.07-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")\n",
    "print(triton_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b0f3ad",
   "metadata": {},
   "source": [
    "**Model creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e740aa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5-bert-uc--2022-09-15-22-33-33-186\n",
      "{'ModelArn': 'arn:aws:sagemaker:us-east-1:622343165275:model/p5-bert-uc--2022-09-15-22-33-33-186', 'ResponseMetadata': {'RequestId': '8ad38848-80af-4a0a-8fc3-79440982caa8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '8ad38848-80af-4a0a-8fc3-79440982caa8', 'content-type': 'application/x-amz-json-1.1', 'content-length': '97', 'date': 'Thu, 15 Sep 2022 22:33:33 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "endpoint_name_p5 = name_from_base(f\"p5-bert-uc-\")\n",
    "print(endpoint_name_p5)\n",
    "\n",
    "container_p5 = {\n",
    "    'Image': triton_image_uri,\n",
    "    'ModelDataUrl': s3_model_path_triton,\n",
    "    'Environment': {\n",
    "        #'SAGEMAKER_PROGRAM' : 'inference.py',\n",
    "        #'SAGEMAKER_SUBMIT_DIRECTORY' : 'code',\n",
    "        'SAGEMAKER_TRITON_DEFAULT_MODEL_NAME': 'bert-uc',\n",
    "        \"SAGEMAKER_TRITON_BATCH_SIZE\": \"16\",\n",
    "        \"SAGEMAKER_TRITON_MAX_BATCH_DELAY\": \"1000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_DEFAULT_BYTE_SIZE\" : \"16777216\", #\"16777216000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_GROWTH_BYTE_SIZE\": \"1048576\"\n",
    "    }\n",
    "}\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=endpoint_name_p5, ExecutionRoleArn=role, PrimaryContainer=container_p5\n",
    ")\n",
    "print(create_model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca7cb57",
   "metadata": {},
   "source": [
    "**Endpoint config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7aadddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint-config/p5-bert-uc--2022-09-15-22-33-33-186\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_name_p5,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g5.8xlarge\", #\"ml.g4dn.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": endpoint_name_p5,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28786c89",
   "metadata": {},
   "source": [
    "**Endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51fb9c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint/p5-bert-uc--2022-09-15-22-33-33-186\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name_p5, EndpointConfigName=endpoint_name_p5\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE:Model:endpoint:Triton:Status: Creating\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"SINGLE:Model:endpoint:Triton:Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Single:model:triton:Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Single:model:triton:Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671b59f",
   "metadata": {},
   "source": [
    "**Now Invoke The endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def tokenize_text(text, enc, max_length=512):\n",
    "    #enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    print(f\"Tokenize:text:why??::max_length={max_length}::Tokenizer={enc}\")\n",
    "    encoded_text = enc(text, padding=\"max_length\", max_length=max_length)\n",
    "    return encoded_text[\"input_ids\"], encoded_text[\"attention_mask\"]\n",
    "\n",
    "\n",
    "def _get_sample_tokenized_text_binary(text, input_names, output_names, enc, max_length=512):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    inputs.append(httpclient.InferInput(input_names[0], [1, max_length], \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[1], [1, max_length], \"INT32\"))\n",
    "    indexed_tokens, attention_mask = tokenize_text(text,enc)\n",
    "\n",
    "    indexed_tokens = np.array(indexed_tokens, dtype=np.int32)\n",
    "    indexed_tokens = np.expand_dims(indexed_tokens, axis=0)\n",
    "    inputs[0].set_data_from_numpy(indexed_tokens, binary_data=True)\n",
    "\n",
    "    attention_mask = np.array(attention_mask, dtype=np.int32)\n",
    "    attention_mask = np.expand_dims(attention_mask, axis=0)\n",
    "    inputs[1].set_data_from_numpy(attention_mask, binary_data=True)\n",
    "\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[0], binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[1], binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "    return request_body, header_length\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_pt(text, enc, max_length=512):\n",
    "    return _get_sample_tokenized_text_binary(\n",
    "        text, [\"INPUT__0\", \"INPUT__1\"], [\"OUTPUT__0\", \"1634__1\"], enc, max_length\n",
    "    )\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_trt(text, enc):\n",
    "    return _get_sample_tokenized_text_binary(text, [\"token_ids\", \"attn_mask\"], [\"output\", \"1634\"], enc, max_length)\n",
    "\n",
    "def get_decoded_text(tensors_tokens, enc):\n",
    "    return_text=tokenizer.batch_decode(gen_tokens)[0]\n",
    "    return return_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "max_seq_length=100 #512\n",
    "text_triton = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\"\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "\n",
    "input_ids, attention_mask = tokenize_text(text_triton, tokenizer, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5, ContentType=\"application/octet-stream\", Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(\n",
    "    torch.tensor(output['outputs'][0]['data']), #tokenizer.decode(unscripted_output[0])\n",
    "    skip_special_tokens=True,\n",
    "    clean_up=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88629d9",
   "metadata": {},
   "source": [
    "#### Use the Binary Headers for Triton - faster but same results - BUT ERRORS out as NO RESPONSE is recieved \n",
    "\n",
    "We can also use binary+json as the payload format to get better performance for the inference call. The specification of this format is provided here.\n",
    "\n",
    "Note: With the binary+json format, we have to specify the length of the request metadata in the header to allow Triton to correctly parse the binary payload. This is done using a custom Content-Type header application/vnd.sagemaker-triton.binary+json;json-header-size={}.\n",
    "\n",
    "Please not, this is different from using Inference-Header-Content-Length header on a stand-alone Triton server since custom headers are not allowed in SageMaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fdeffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leverage the Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})::max_seq_length=512:: create above when creating the model \n",
      "Tokenize:text:why??::max_length=512::Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "Error in parsing respinse -- probably the body is empty\n",
      "CPU times: user 3.46 ms, sys: 9.35 ms, total: 12.8 ms\n",
      "Wall time: 32.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "max_seq_length=512\n",
    "text_triton = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\"\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "\n",
    "#input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "request_body, header_length = get_sample_tokenized_text_binary_pt(text_triton, enc) # this returns \n",
    "\n",
    "\n",
    "response_binary = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5, \n",
    "    ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(header_length), \n",
    "    Body=request_body\n",
    ")\n",
    "\n",
    "# Parse json header size length from the response\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "\n",
    "try:\n",
    "    # Read response body\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(\n",
    "        response_binary[\"Body\"].read(), header_length=int(header_length_str)\n",
    "    )\n",
    "    output0_data = result.as_numpy(\"OUTPUT__0\")\n",
    "    output1_data = result.as_numpy(\"1634__1\")\n",
    "    print(output0_data)\n",
    "    print(output1_data)\n",
    "except:\n",
    "    print(\"Error in parsing respinse -- probably the body is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "122a0242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p5-bert-uc--2022-09-08-03-02-53-774'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name_p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ecfa4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leverage the Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})::max_seq_length=512:: create above when creating the model \n",
      "Tokenize:text:why??::max_length=512::Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "CPU times: user 14 s, sys: 1.07 s, total: 15.1 s\n",
      "Wall time: 28.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_name', 'model_version', 'outputs'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "max_seq_length=512\n",
    "text_triton = \"\"\"This is a creative writing exercise. Below, you'll be given a prompt. Your story should be based on the prompt.\n",
    "\n",
    "Prompt: A scary story about a haunted mouse\n",
    "Story: On a dark and stormy night, the mouse crept in the shadows. \"\"\"\n",
    "\n",
    "\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids}, # -- enc.tokenize(text)}, #\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "max_run = 100\n",
    "for ii in range(0, max_run):\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name_p5, ContentType=\"application/octet-stream\", Body=json.dumps(payload)\n",
    "    )\n",
    "\n",
    "    output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "    # -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "    output_dict.keys()\n",
    "\n",
    "    #enc.decode(output_dict['outputs'][0]['data'], skip_special_tokens=True)\n",
    "output_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d6340fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'OUTPUT__0',\n",
       " 'datatype': 'FP32',\n",
       " 'shape': [1, 512, 768],\n",
       " 'data': [-0.15243282914161682,\n",
       "  -0.8572331666946411,\n",
       "  0.06608188152313232,\n",
       "  -0.20899571478366852,\n",
       "  0.35779935121536255,\n",
       "  -0.4324319064617157,\n",
       "  0.21307486295700073,\n",
       "  0.7328435778617859,\n",
       "  0.2850395441055298,\n",
       "  -0.8913273811340332,\n",
       "  0.2898162603378296,\n",
       "  -0.2516830265522003,\n",
       "  0.17877909541130066,\n",
       "  0.22467152774333954,\n",
       "  -0.16646161675453186,\n",
       "  0.21520552039146423,\n",
       "  0.4105544686317444,\n",
       "  0.49988511204719543,\n",
       "  0.15959863364696503,\n",
       "  0.11675862967967987,\n",
       "  0.012811945751309395,\n",
       "  -0.6604794859886169,\n",
       "  0.46912506222724915,\n",
       "  0.11688332259654999,\n",
       "  0.15712383389472961,\n",
       "  -0.03815995156764984,\n",
       "  -0.13969361782073975,\n",
       "  0.015787124633789062,\n",
       "  0.11993402242660522,\n",
       "  0.3402771055698395,\n",
       "  -0.6780798435211182,\n",
       "  0.1458730399608612,\n",
       "  -0.25922656059265137,\n",
       "  -0.7832548022270203,\n",
       "  0.28116920590400696,\n",
       "  -0.12131515890359879,\n",
       "  -0.28475871682167053,\n",
       "  -0.2089376002550125,\n",
       "  -0.11570572853088379,\n",
       "  0.35242488980293274,\n",
       "  -0.9599204659461975,\n",
       "  0.19939231872558594,\n",
       "  0.09761316329240799,\n",
       "  -0.25746431946754456,\n",
       "  0.2714739441871643,\n",
       "  -0.4958275854587555,\n",
       "  -4.28070592880249,\n",
       "  0.0795796662569046,\n",
       "  0.06400274485349655,\n",
       "  -0.8140904307365417,\n",
       "  0.21850654482841492,\n",
       "  0.014872162602841854,\n",
       "  -0.38559287786483765,\n",
       "  0.49034759402275085,\n",
       "  0.21157188713550568,\n",
       "  0.28455108404159546,\n",
       "  -0.22176732122898102,\n",
       "  0.22864080965518951,\n",
       "  -0.060361556708812714,\n",
       "  -0.20122043788433075,\n",
       "  -0.005756697151809931,\n",
       "  -0.06988131254911423,\n",
       "  -0.15562108159065247,\n",
       "  -0.004894986283034086,\n",
       "  -0.7175312638282776,\n",
       "  0.5078800320625305,\n",
       "  -0.017568115144968033,\n",
       "  0.20313388109207153,\n",
       "  -0.27161484956741333,\n",
       "  0.59983891248703,\n",
       "  -0.24598833918571472,\n",
       "  0.18726643919944763,\n",
       "  0.17724545300006866,\n",
       "  -0.356765478849411,\n",
       "  0.3893219530582428,\n",
       "  0.04006847366690636,\n",
       "  -0.38726016879081726,\n",
       "  0.016088290140032768,\n",
       "  -0.6229373216629028,\n",
       "  0.013894503936171532,\n",
       "  -0.44776278734207153,\n",
       "  0.755653977394104,\n",
       "  0.46263158321380615,\n",
       "  0.047012973576784134,\n",
       "  0.4246334731578827,\n",
       "  0.15268069505691528,\n",
       "  -0.789059579372406,\n",
       "  0.0030534849502146244,\n",
       "  0.30108505487442017,\n",
       "  0.3011099696159363,\n",
       "  -0.6517355442047119,\n",
       "  -0.3106408715248108,\n",
       "  -0.8016434907913208,\n",
       "  0.3920685350894928,\n",
       "  0.21406258642673492,\n",
       "  0.052744146436452866,\n",
       "  -0.09847257286310196,\n",
       "  0.012269517406821251,\n",
       "  0.3281860649585724,\n",
       "  0.9568153023719788,\n",
       "  0.054322369396686554,\n",
       "  -0.5601522326469421,\n",
       "  0.14691179990768433,\n",
       "  -0.6472994089126587,\n",
       "  -0.06023532897233963,\n",
       "  0.30683863162994385,\n",
       "  0.23232325911521912,\n",
       "  -0.04246249049901962,\n",
       "  -0.2844262719154358,\n",
       "  -1.803192138671875,\n",
       "  -0.045831985771656036,\n",
       "  -0.003260977566242218,\n",
       "  0.21598969399929047,\n",
       "  -0.5739086270332336,\n",
       "  0.16243724524974823,\n",
       "  -0.22761230170726776,\n",
       "  0.6652820110321045,\n",
       "  -0.298556923866272,\n",
       "  0.06696085631847382,\n",
       "  -0.23198053240776062,\n",
       "  -0.18249568343162537,\n",
       "  -0.4174838364124298,\n",
       "  -0.09105788171291351,\n",
       "  -0.5179993510246277,\n",
       "  0.4876752197742462,\n",
       "  0.4783645570278168,\n",
       "  0.1439400464296341,\n",
       "  0.3334556818008423,\n",
       "  0.25536584854125977,\n",
       "  -0.21909332275390625,\n",
       "  0.6439536213874817,\n",
       "  0.20453940331935883,\n",
       "  -0.37209081649780273,\n",
       "  -0.17049318552017212,\n",
       "  -0.3931882977485657,\n",
       "  1.097961664199829,\n",
       "  -0.16415078938007355,\n",
       "  -0.18966242671012878,\n",
       "  -0.38879573345184326,\n",
       "  0.17658215761184692,\n",
       "  0.06191803142428398,\n",
       "  -0.11129635572433472,\n",
       "  -2.5897436141967773,\n",
       "  0.8232522010803223,\n",
       "  0.9554612040519714,\n",
       "  0.2858097553253174,\n",
       "  0.004961827769875526,\n",
       "  -0.2980957329273224,\n",
       "  -0.6197496652603149,\n",
       "  0.4078480899333954,\n",
       "  0.43433651328086853,\n",
       "  0.44900840520858765,\n",
       "  -0.298801451921463,\n",
       "  0.2750507593154907,\n",
       "  -0.6649825572967529,\n",
       "  0.4650048613548279,\n",
       "  -0.37900495529174805,\n",
       "  0.23983296751976013,\n",
       "  0.1963275820016861,\n",
       "  0.18936653435230255,\n",
       "  0.08404063433408737,\n",
       "  0.27934569120407104,\n",
       "  -0.1847696453332901,\n",
       "  0.2775258421897888,\n",
       "  -0.03290119022130966,\n",
       "  0.08018647134304047,\n",
       "  0.4324783980846405,\n",
       "  0.34535008668899536,\n",
       "  -0.4332107901573181,\n",
       "  -0.216921865940094,\n",
       "  -0.15295131504535675,\n",
       "  0.2409810721874237,\n",
       "  1.0469696521759033,\n",
       "  0.36875292658805847,\n",
       "  0.08053147792816162,\n",
       "  -0.1223502978682518,\n",
       "  -0.2162165343761444,\n",
       "  -0.007359195034950972,\n",
       "  0.5893856287002563,\n",
       "  -0.18758779764175415,\n",
       "  -0.8738098740577698,\n",
       "  0.30574169754981995,\n",
       "  -0.13024497032165527,\n",
       "  -0.09229726344347,\n",
       "  0.07358723878860474,\n",
       "  -0.3273221254348755,\n",
       "  0.3707204759120941,\n",
       "  -0.09124206751585007,\n",
       "  -0.07653260976076126,\n",
       "  -0.38909420371055603,\n",
       "  -0.3068927526473999,\n",
       "  -0.5193188190460205,\n",
       "  0.29507753252983093,\n",
       "  0.10124936699867249,\n",
       "  0.4992099404335022,\n",
       "  -0.5116150975227356,\n",
       "  0.0808495581150055,\n",
       "  -0.3332512378692627,\n",
       "  -0.3916238248348236,\n",
       "  -0.29075372219085693,\n",
       "  0.08020149916410446,\n",
       "  -0.33299875259399414,\n",
       "  0.5210301280021667,\n",
       "  0.22531406581401825,\n",
       "  -0.21531414985656738,\n",
       "  3.9804553985595703,\n",
       "  -0.5335700511932373,\n",
       "  -0.6236492395401001,\n",
       "  0.3646713197231293,\n",
       "  0.3299594521522522,\n",
       "  -0.7218930721282959,\n",
       "  0.11543698608875275,\n",
       "  -0.007148232776671648,\n",
       "  0.5000238418579102,\n",
       "  0.11779721081256866,\n",
       "  0.23821154236793518,\n",
       "  0.3014300465583801,\n",
       "  0.10538209229707718,\n",
       "  0.37916961312294006,\n",
       "  0.18390344083309174,\n",
       "  -0.5240735411643982,\n",
       "  0.3078731894493103,\n",
       "  -0.8637978434562683,\n",
       "  -0.07996610552072525,\n",
       "  -0.9679317474365234,\n",
       "  0.19479244947433472,\n",
       "  -0.27941086888313293,\n",
       "  0.3579581081867218,\n",
       "  0.30736058950424194,\n",
       "  -1.7784301042556763,\n",
       "  -0.35053661465644836,\n",
       "  -0.06332805752754211,\n",
       "  0.20748697221279144,\n",
       "  0.14578208327293396,\n",
       "  -0.3111460506916046,\n",
       "  0.07201452553272247,\n",
       "  -0.6581940054893494,\n",
       "  -0.6154274940490723,\n",
       "  -0.09685604274272919,\n",
       "  -0.17917901277542114,\n",
       "  0.18489520251750946,\n",
       "  0.566371738910675,\n",
       "  0.33499693870544434,\n",
       "  0.6630157232284546,\n",
       "  -0.14674519002437592,\n",
       "  0.11833595484495163,\n",
       "  0.3510623872280121,\n",
       "  0.13926023244857788,\n",
       "  0.5620833039283752,\n",
       "  -0.4351637363433838,\n",
       "  0.567243218421936,\n",
       "  0.13841907680034637,\n",
       "  0.7434300184249878,\n",
       "  0.11254368722438812,\n",
       "  0.32779985666275024,\n",
       "  0.41057053208351135,\n",
       "  -0.3029719591140747,\n",
       "  -0.2382582277059555,\n",
       "  -0.11079960316419601,\n",
       "  0.015436003915965557,\n",
       "  -0.13279466331005096,\n",
       "  0.12257592380046844,\n",
       "  -0.3194899559020996,\n",
       "  0.43891462683677673,\n",
       "  -0.6943170428276062,\n",
       "  -0.05838284641504288,\n",
       "  0.3810212016105652,\n",
       "  -0.09472791850566864,\n",
       "  0.3196665942668915,\n",
       "  0.11023896187543869,\n",
       "  -0.20110729336738586,\n",
       "  -0.19630540907382965,\n",
       "  -0.733989417552948,\n",
       "  -2.283050060272217,\n",
       "  -0.1596091091632843,\n",
       "  -0.3896175026893616,\n",
       "  0.25501734018325806,\n",
       "  0.5485239624977112,\n",
       "  0.7279982566833496,\n",
       "  -0.2977728843688965,\n",
       "  0.27647411823272705,\n",
       "  0.7247763276100159,\n",
       "  -0.625706136226654,\n",
       "  0.6716095805168152,\n",
       "  0.7512229681015015,\n",
       "  -0.6151925921440125,\n",
       "  0.5348860025405884,\n",
       "  0.26652613282203674,\n",
       "  -0.2668118476867676,\n",
       "  -0.059999823570251465,\n",
       "  -0.916610836982727,\n",
       "  0.05203899368643761,\n",
       "  -0.5905131101608276,\n",
       "  -0.5954939126968384,\n",
       "  -0.02916477434337139,\n",
       "  -0.05308451130986214,\n",
       "  0.7269306182861328,\n",
       "  0.64029461145401,\n",
       "  0.4839937090873718,\n",
       "  -0.0747174471616745,\n",
       "  -0.12876608967781067,\n",
       "  -0.3492620587348938,\n",
       "  0.42400145530700684,\n",
       "  0.31635794043540955,\n",
       "  0.001425330643542111,\n",
       "  0.37645307183265686,\n",
       "  -0.08180449157953262,\n",
       "  -0.682857096195221,\n",
       "  -2.667266368865967,\n",
       "  0.16403107345104218,\n",
       "  0.10986682027578354,\n",
       "  -0.3569868206977844,\n",
       "  -0.027537843212485313,\n",
       "  0.2773939073085785,\n",
       "  0.38499656319618225,\n",
       "  -0.008390780538320541,\n",
       "  -0.4786089062690735,\n",
       "  -0.09760541468858719,\n",
       "  0.24313293397426605,\n",
       "  -0.45595282316207886,\n",
       "  0.3337545096874237,\n",
       "  -0.010193522088229656,\n",
       "  0.6302138566970825,\n",
       "  0.01677335426211357,\n",
       "  0.34828659892082214,\n",
       "  -0.5686216950416565,\n",
       "  0.010367066599428654,\n",
       "  -0.13441316783428192,\n",
       "  -0.3208213150501251,\n",
       "  0.19600138068199158,\n",
       "  0.3707866668701172,\n",
       "  -0.22076064348220825,\n",
       "  0.5413828492164612,\n",
       "  0.6409174799919128,\n",
       "  -0.800566554069519,\n",
       "  -0.21035903692245483,\n",
       "  0.12587518990039825,\n",
       "  -0.13108915090560913,\n",
       "  0.405699223279953,\n",
       "  -0.4599815905094147,\n",
       "  -0.4158557951450348,\n",
       "  0.1859418898820877,\n",
       "  -0.48929986357688904,\n",
       "  -0.014476576820015907,\n",
       "  0.5688996911048889,\n",
       "  -0.1462414562702179,\n",
       "  0.6768046617507935,\n",
       "  0.3780023455619812,\n",
       "  -0.16517241299152374,\n",
       "  0.5860856771469116,\n",
       "  0.04229560121893883,\n",
       "  -0.14841297268867493,\n",
       "  0.5961641669273376,\n",
       "  0.050503432750701904,\n",
       "  0.7350917458534241,\n",
       "  -0.3551936745643616,\n",
       "  0.2134319543838501,\n",
       "  0.7498502135276794,\n",
       "  -0.06756069511175156,\n",
       "  0.2406913787126541,\n",
       "  1.6315383911132812,\n",
       "  0.03517923504114151,\n",
       "  0.42837265133857727,\n",
       "  0.13128745555877686,\n",
       "  0.004562667105346918,\n",
       "  -0.0020802682265639305,\n",
       "  -0.5440433621406555,\n",
       "  0.45915353298187256,\n",
       "  0.6549606323242188,\n",
       "  -0.8992667198181152,\n",
       "  -0.06954380124807358,\n",
       "  -0.3308899998664856,\n",
       "  0.7643892168998718,\n",
       "  -0.8476575613021851,\n",
       "  0.15809689462184906,\n",
       "  -0.411735862493515,\n",
       "  0.010811352171003819,\n",
       "  -0.1143619641661644,\n",
       "  0.33857402205467224,\n",
       "  0.22135883569717407,\n",
       "  -0.4099784195423126,\n",
       "  -1.6249817609786987,\n",
       "  0.3434310555458069,\n",
       "  -0.02272789552807808,\n",
       "  -0.3741368353366852,\n",
       "  0.16478930413722992,\n",
       "  -0.24276229739189148,\n",
       "  -0.3600810468196869,\n",
       "  0.1560140699148178,\n",
       "  -0.3518632650375366,\n",
       "  -0.15955300629138947,\n",
       "  0.3054552972316742,\n",
       "  -0.6356754302978516,\n",
       "  -0.4160648584365845,\n",
       "  0.10241243988275528,\n",
       "  0.1789943128824234,\n",
       "  -0.6628385186195374,\n",
       "  -0.43797510862350464,\n",
       "  0.09305015951395035,\n",
       "  0.21994896233081818,\n",
       "  0.2351069301366806,\n",
       "  0.2470349371433258,\n",
       "  -0.7779158353805542,\n",
       "  -0.07482749968767166,\n",
       "  0.042539793998003006,\n",
       "  -1.3215032815933228,\n",
       "  0.29316550493240356,\n",
       "  -0.11797415465116501,\n",
       "  0.5045604109764099,\n",
       "  0.36977142095565796,\n",
       "  0.12047497183084488,\n",
       "  -0.2272309958934784,\n",
       "  -0.4634229838848114,\n",
       "  0.03910891339182854,\n",
       "  -0.42650309205055237,\n",
       "  0.12236924469470978,\n",
       "  0.0734814777970314,\n",
       "  0.23430900275707245,\n",
       "  -0.4466637670993805,\n",
       "  -0.26380473375320435,\n",
       "  -0.4400947093963623,\n",
       "  -0.00739049119874835,\n",
       "  1.060275912284851,\n",
       "  -0.47253018617630005,\n",
       "  0.04528389126062393,\n",
       "  0.8045607209205627,\n",
       "  0.07821834087371826,\n",
       "  -0.37794145941734314,\n",
       "  0.49531713128089905,\n",
       "  0.009510708041489124,\n",
       "  0.17018736898899078,\n",
       "  -0.4015081226825714,\n",
       "  0.3611564338207245,\n",
       "  -0.15230809152126312,\n",
       "  0.14244310557842255,\n",
       "  -0.23516149818897247,\n",
       "  0.19474199414253235,\n",
       "  0.013688655570149422,\n",
       "  0.5158392786979675,\n",
       "  -0.20714668929576874,\n",
       "  -0.4269808232784271,\n",
       "  -0.1989830732345581,\n",
       "  0.019452707841992378,\n",
       "  0.003826805157586932,\n",
       "  -0.89957195520401,\n",
       "  -0.4286869168281555,\n",
       "  -0.0382392518222332,\n",
       "  0.38160526752471924,\n",
       "  0.5184934735298157,\n",
       "  0.03202255070209503,\n",
       "  -0.6420595049858093,\n",
       "  -0.1360992044210434,\n",
       "  0.050308577716350555,\n",
       "  0.3413587510585785,\n",
       "  -0.40859586000442505,\n",
       "  0.12311729788780212,\n",
       "  0.19384804368019104,\n",
       "  0.28185132145881653,\n",
       "  0.13951259851455688,\n",
       "  0.5814095139503479,\n",
       "  -0.3154950737953186,\n",
       "  -0.1854190230369568,\n",
       "  0.06399369239807129,\n",
       "  0.25282222032546997,\n",
       "  -0.05173686891794205,\n",
       "  -0.21610401570796967,\n",
       "  -0.03656230866909027,\n",
       "  -0.22397226095199585,\n",
       "  -0.007589278277009726,\n",
       "  0.1626456081867218,\n",
       "  -1.9365695714950562,\n",
       "  -0.10576067119836807,\n",
       "  0.590091347694397,\n",
       "  -0.07427757233381271,\n",
       "  0.17707780003547668,\n",
       "  -0.2830815315246582,\n",
       "  0.16561488807201385,\n",
       "  0.3820725083351135,\n",
       "  -0.10643642395734787,\n",
       "  -0.09023184329271317,\n",
       "  -0.15113085508346558,\n",
       "  0.6557567119598389,\n",
       "  0.11127658188343048,\n",
       "  0.1654430776834488,\n",
       "  -0.09123630821704865,\n",
       "  -0.6255208253860474,\n",
       "  -0.4871487617492676,\n",
       "  -0.34839850664138794,\n",
       "  0.10916300117969513,\n",
       "  -0.9921050071716309,\n",
       "  -0.2253103256225586,\n",
       "  0.6314945220947266,\n",
       "  0.7647891044616699,\n",
       "  0.1289629340171814,\n",
       "  0.03854874148964882,\n",
       "  -0.32970431447029114,\n",
       "  -0.002516691107302904,\n",
       "  0.3706390857696533,\n",
       "  0.05061403289437294,\n",
       "  0.24953855574131012,\n",
       "  0.35177135467529297,\n",
       "  0.12793877720832825,\n",
       "  -0.8429774641990662,\n",
       "  0.06458117067813873,\n",
       "  0.39192691445350647,\n",
       "  0.40299156308174133,\n",
       "  0.41197773814201355,\n",
       "  -0.23538699746131897,\n",
       "  0.43065574765205383,\n",
       "  0.43894556164741516,\n",
       "  -0.6606647968292236,\n",
       "  0.35109591484069824,\n",
       "  0.5190305113792419,\n",
       "  0.6520794034004211,\n",
       "  0.8571969866752625,\n",
       "  -0.05022159591317177,\n",
       "  -0.10029426962137222,\n",
       "  0.2952761650085449,\n",
       "  -0.32723426818847656,\n",
       "  -0.017702119424939156,\n",
       "  -0.7253603339195251,\n",
       "  -0.7763994336128235,\n",
       "  -0.0747443363070488,\n",
       "  -0.35449352860450745,\n",
       "  -0.198677659034729,\n",
       "  -0.49206504225730896,\n",
       "  0.38733184337615967,\n",
       "  0.1457296758890152,\n",
       "  -0.9076860547065735,\n",
       "  -0.33420440554618835,\n",
       "  0.5267676115036011,\n",
       "  -0.07851012051105499,\n",
       "  -0.43514230847358704,\n",
       "  -0.43984705209732056,\n",
       "  -0.08559336513280869,\n",
       "  -1.0786504745483398,\n",
       "  -0.28133469820022583,\n",
       "  -0.07433544844388962,\n",
       "  0.015066095627844334,\n",
       "  0.20733742415905,\n",
       "  0.11163754761219025,\n",
       "  -0.02526504173874855,\n",
       "  -0.7287487983703613,\n",
       "  0.19242285192012787,\n",
       "  -0.4180862605571747,\n",
       "  -0.29124394059181213,\n",
       "  0.132492333650589,\n",
       "  -0.1641431599855423,\n",
       "  0.5331347584724426,\n",
       "  -0.6004188060760498,\n",
       "  0.3266528248786926,\n",
       "  0.19985897839069366,\n",
       "  0.2508074641227722,\n",
       "  0.5183570981025696,\n",
       "  -0.6566883325576782,\n",
       "  0.011749832890927792,\n",
       "  -0.4450083076953888,\n",
       "  0.22919724881649017,\n",
       "  0.30244335532188416,\n",
       "  0.12190672755241394,\n",
       "  -0.48163577914237976,\n",
       "  -0.6678341031074524,\n",
       "  -0.05269142985343933,\n",
       "  0.14905701577663422,\n",
       "  -0.26032546162605286,\n",
       "  -0.28518247604370117,\n",
       "  0.04718537628650665,\n",
       "  0.5703840851783752,\n",
       "  -0.32296475768089294,\n",
       "  -0.767652690410614,\n",
       "  -0.028027929365634918,\n",
       "  0.4003502130508423,\n",
       "  0.7045083045959473,\n",
       "  -0.0024386586155742407,\n",
       "  0.33113357424736023,\n",
       "  0.47623196244239807,\n",
       "  0.6452591419219971,\n",
       "  -0.6414557099342346,\n",
       "  -0.4135698676109314,\n",
       "  -0.2912571430206299,\n",
       "  0.2803230583667755,\n",
       "  -0.25887420773506165,\n",
       "  -0.2568710446357727,\n",
       "  0.25726157426834106,\n",
       "  -0.11538080871105194,\n",
       "  -0.8551483750343323,\n",
       "  -0.24193046987056732,\n",
       "  -0.31402918696403503,\n",
       "  1.4807443618774414,\n",
       "  0.3956575393676758,\n",
       "  -0.33006277680397034,\n",
       "  -0.28906020522117615,\n",
       "  0.39670252799987793,\n",
       "  0.5810874700546265,\n",
       "  -0.08746033906936646,\n",
       "  0.7076026797294617,\n",
       "  -0.49196168780326843,\n",
       "  0.9828351140022278,\n",
       "  -0.11483540385961533,\n",
       "  0.5720252394676208,\n",
       "  -0.5338782668113708,\n",
       "  -0.3397670388221741,\n",
       "  1.0628236532211304,\n",
       "  0.22742335498332977,\n",
       "  0.245201975107193,\n",
       "  -0.055027008056640625,\n",
       "  -0.4301733672618866,\n",
       "  -0.11962784081697464,\n",
       "  -0.5559842586517334,\n",
       "  0.9395849108695984,\n",
       "  0.8768144845962524,\n",
       "  0.3721594214439392,\n",
       "  -0.2621835172176361,\n",
       "  0.6894754767417908,\n",
       "  0.031490884721279144,\n",
       "  -0.45206230878829956,\n",
       "  0.017423762008547783,\n",
       "  1.2395076751708984,\n",
       "  -0.6819962859153748,\n",
       "  -0.21774542331695557,\n",
       "  0.2407231628894806,\n",
       "  0.48617616295814514,\n",
       "  -0.7289584279060364,\n",
       "  -0.18832236528396606,\n",
       "  -0.868733823299408,\n",
       "  -0.07730326801538467,\n",
       "  -0.17490480840206146,\n",
       "  -0.49257999658584595,\n",
       "  0.1646927446126938,\n",
       "  -0.012394888326525688,\n",
       "  0.97123783826828,\n",
       "  -0.06959221512079239,\n",
       "  -1.0203454494476318,\n",
       "  0.5534039735794067,\n",
       "  -0.6465563774108887,\n",
       "  -0.32650575041770935,\n",
       "  0.1482006311416626,\n",
       "  0.10388380289077759,\n",
       "  0.2709469199180603,\n",
       "  -0.18422652781009674,\n",
       "  -0.26728710532188416,\n",
       "  0.1764126867055893,\n",
       "  0.383524626493454,\n",
       "  0.12405954301357269,\n",
       "  0.6090409755706787,\n",
       "  0.06067296117544174,\n",
       "  -0.26954978704452515,\n",
       "  0.08975710719823837,\n",
       "  -0.42179277539253235,\n",
       "  0.24224570393562317,\n",
       "  0.41087329387664795,\n",
       "  0.23719225823879242,\n",
       "  0.6771267056465149,\n",
       "  -0.16299887001514435,\n",
       "  0.19770996272563934,\n",
       "  0.04112868010997772,\n",
       "  0.28650322556495667,\n",
       "  -0.4513266384601593,\n",
       "  -0.20538204908370972,\n",
       "  0.7205323576927185,\n",
       "  -0.019271565601229668,\n",
       "  0.8237189054489136,\n",
       "  0.3385160267353058,\n",
       "  0.7132264375686646,\n",
       "  0.7630184888839722,\n",
       "  -0.13469535112380981,\n",
       "  -0.6349261403083801,\n",
       "  -1.4645342826843262,\n",
       "  0.3074992299079895,\n",
       "  0.23793555796146393,\n",
       "  0.6368815898895264,\n",
       "  -0.3870506286621094,\n",
       "  0.2774500548839569,\n",
       "  0.9369627237319946,\n",
       "  -0.15526948869228363,\n",
       "  -0.14886446297168732,\n",
       "  -0.368557333946228,\n",
       "  0.4437929093837738,\n",
       "  0.1247909739613533,\n",
       "  0.7323305606842041,\n",
       "  -1.0264643430709839,\n",
       "  0.049332935363054276,\n",
       "  -0.07287430763244629,\n",
       "  1.1246798038482666,\n",
       "  -0.25645190477371216,\n",
       "  0.79436856508255,\n",
       "  -0.26167434453964233,\n",
       "  0.21237047016620636,\n",
       "  -0.1532057672739029,\n",
       "  -0.02862439677119255,\n",
       "  -0.4626915156841278,\n",
       "  -0.8138589859008789,\n",
       "  -0.31271106004714966,\n",
       "  0.08624204248189926,\n",
       "  -0.10287543386220932,\n",
       "  -0.29928845167160034,\n",
       "  0.15514004230499268,\n",
       "  -0.2512807548046112,\n",
       "  0.45485618710517883,\n",
       "  -0.7099696397781372,\n",
       "  0.2852531969547272,\n",
       "  -0.3635960519313812,\n",
       "  0.4106740951538086,\n",
       "  -0.03722316026687622,\n",
       "  0.4611254632472992,\n",
       "  0.26617658138275146,\n",
       "  -0.12129662930965424,\n",
       "  0.018484685570001602,\n",
       "  0.7792474627494812,\n",
       "  -0.7508952021598816,\n",
       "  0.3767417371273041,\n",
       "  0.3458622992038727,\n",
       "  -0.017128678038716316,\n",
       "  1.0647449493408203,\n",
       "  -0.12255655974149704,\n",
       "  0.701700747013092,\n",
       "  -0.17210090160369873,\n",
       "  -0.21266409754753113,\n",
       "  0.3220290541648865,\n",
       "  1.042075514793396,\n",
       "  0.44450265169143677,\n",
       "  0.2265007495880127,\n",
       "  -0.18980370461940765,\n",
       "  0.18499352037906647,\n",
       "  -0.15596164762973785,\n",
       "  -0.0973033607006073,\n",
       "  -0.4193395674228668,\n",
       "  -0.5341764688491821,\n",
       "  0.3734762370586395,\n",
       "  -0.46815618872642517,\n",
       "  -0.15334327518939972,\n",
       "  1.063309907913208,\n",
       "  -0.30913424491882324,\n",
       "  0.266042560338974,\n",
       "  0.44362929463386536,\n",
       "  -0.10186593979597092,\n",
       "  -0.6078144311904907,\n",
       "  -0.5296705365180969,\n",
       "  -0.1086951345205307,\n",
       "  0.029407847672700882,\n",
       "  0.13378363847732544,\n",
       "  0.576744556427002,\n",
       "  -0.3269336521625519,\n",
       "  0.34273573756217957,\n",
       "  0.6779901385307312,\n",
       "  0.2496640533208847,\n",
       "  -0.1499091535806656,\n",
       "  -0.08570697158575058,\n",
       "  0.3204309940338135,\n",
       "  0.08414646238088608,\n",
       "  -0.646040678024292,\n",
       "  0.3570067882537842,\n",
       "  -5.690296649932861,\n",
       "  0.41276815533638,\n",
       "  -0.23042500019073486,\n",
       "  0.13111449778079987,\n",
       "  -0.4327654540538788,\n",
       "  -0.989452600479126,\n",
       "  -0.2599603831768036,\n",
       "  -0.15610752999782562,\n",
       "  -0.38662955164909363,\n",
       "  -0.4319131672382355,\n",
       "  -0.10625971853733063,\n",
       "  0.46662232279777527,\n",
       "  0.17167523503303528,\n",
       "  -0.26219871640205383,\n",
       "  -0.01638292521238327,\n",
       "  0.8044725060462952,\n",
       "  -0.7595658898353577,\n",
       "  -0.5881166458129883,\n",
       "  -0.025703895837068558,\n",
       "  -0.2029799222946167,\n",
       "  0.3818010985851288,\n",
       "  -0.1393527388572693,\n",
       "  -0.11042293906211853,\n",
       "  1.4981578588485718,\n",
       "  -0.0036011619959026575,\n",
       "  -0.08999548852443695,\n",
       "  0.0007514312164857984,\n",
       "  -0.3181125223636627,\n",
       "  0.2870157063007355,\n",
       "  -0.11600325256586075,\n",
       "  0.09765161573886871,\n",
       "  0.4179441034793854,\n",
       "  0.28066346049308777,\n",
       "  0.39467859268188477,\n",
       "  0.13252809643745422,\n",
       "  0.18732275068759918,\n",
       "  0.5330065488815308,\n",
       "  -0.005108908750116825,\n",
       "  0.14801445603370667,\n",
       "  0.8875568509101868,\n",
       "  0.8857049942016602,\n",
       "  0.0008163273450918496,\n",
       "  0.22233706712722778,\n",
       "  0.14635850489139557,\n",
       "  -0.3280401825904846,\n",
       "  -1.1395660638809204,\n",
       "  -0.019569920375943184,\n",
       "  0.05176907405257225,\n",
       "  0.20769082009792328,\n",
       "  -0.738433837890625,\n",
       "  0.0810212641954422,\n",
       "  -0.57448810338974,\n",
       "  0.01890065334737301,\n",
       "  -0.6642919778823853,\n",
       "  -0.23686735332012177,\n",
       "  0.4988414943218231,\n",
       "  -0.4114721119403839,\n",
       "  0.1259208470582962,\n",
       "  0.20167165994644165,\n",
       "  -0.038704901933670044,\n",
       "  0.9287362694740295,\n",
       "  -0.6229997873306274,\n",
       "  -0.25441837310791016,\n",
       "  -0.8440266251564026,\n",
       "  0.5294130444526672,\n",
       "  0.16173341870307922,\n",
       "  -0.7345454096794128,\n",
       "  0.36443933844566345,\n",
       "  0.5440770983695984,\n",
       "  -0.24436499178409576,\n",
       "  -0.22731997072696686,\n",
       "  0.36946284770965576,\n",
       "  -0.3556789457798004,\n",
       "  -0.10366591066122055,\n",
       "  -0.7346314787864685,\n",
       "  0.19080977141857147,\n",
       "  0.3967592418193817,\n",
       "  -0.04712070897221565,\n",
       "  -0.21215929090976715,\n",
       "  -0.08550339192152023,\n",
       "  0.19921128451824188,\n",
       "  -0.03884485736489296,\n",
       "  0.05804602429270744,\n",
       "  1.0955346822738647,\n",
       "  -1.2348569631576538,\n",
       "  -0.49811726808547974,\n",
       "  -0.2274211347103119,\n",
       "  -0.7072733640670776,\n",
       "  0.46943145990371704,\n",
       "  -0.28947630524635315,\n",
       "  0.5181368589401245,\n",
       "  0.2877310514450073,\n",
       "  -0.14419975876808167,\n",
       "  -0.09450389444828033,\n",
       "  -0.17006058990955353,\n",
       "  -0.4197314977645874,\n",
       "  -0.24286271631717682,\n",
       "  1.2148160934448242,\n",
       "  -0.03178662061691284,\n",
       "  0.042943235486745834,\n",
       "  -0.36007633805274963,\n",
       "  0.5239415168762207,\n",
       "  -0.8245298266410828,\n",
       "  0.015807142481207848,\n",
       "  0.26179471611976624,\n",
       "  0.556049108505249,\n",
       "  -0.3179343640804291,\n",
       "  0.12528179585933685,\n",
       "  -0.5196822285652161,\n",
       "  0.03170362114906311,\n",
       "  0.41035670042037964,\n",
       "  -0.9063966870307922,\n",
       "  0.07459063827991486,\n",
       "  0.039600737392902374,\n",
       "  -0.04662210866808891,\n",
       "  0.008652030490338802,\n",
       "  -0.3990488648414612,\n",
       "  -1.518363118171692,\n",
       "  -0.2523789405822754,\n",
       "  0.16996394097805023,\n",
       "  0.5184571146965027,\n",
       "  0.07396390289068222,\n",
       "  0.26741066575050354,\n",
       "  -0.016938261687755585,\n",
       "  -0.1327054798603058,\n",
       "  -0.11027899384498596,\n",
       "  -0.1153007447719574,\n",
       "  0.1325850486755371,\n",
       "  -0.19647115468978882,\n",
       "  -0.9545804262161255,\n",
       "  -0.17417313158512115,\n",
       "  0.7408426403999329,\n",
       "  0.2696540355682373,\n",
       "  0.3485738933086395,\n",
       "  0.022285165265202522,\n",
       "  0.16813504695892334,\n",
       "  -0.10243787616491318,\n",
       "  0.01871873438358307,\n",
       "  0.4852330982685089,\n",
       "  0.4862951338291168,\n",
       "  -0.7041104435920715,\n",
       "  0.33142268657684326,\n",
       "  -0.006252328399568796,\n",
       "  0.2609426975250244,\n",
       "  0.738551139831543,\n",
       "  -0.7768146395683289,\n",
       "  0.6602467894554138,\n",
       "  0.5471489429473877,\n",
       "  0.40082600712776184,\n",
       "  -0.46358439326286316,\n",
       "  -0.3200080096721649,\n",
       "  -0.13953787088394165,\n",
       "  0.8278697729110718,\n",
       "  -0.4627791941165924,\n",
       "  -0.32709482312202454,\n",
       "  0.6943374872207642,\n",
       "  0.7043707966804504,\n",
       "  -0.06588182598352432,\n",
       "  0.9223544597625732,\n",
       "  -0.25970831513404846,\n",
       "  -0.09014131873846054,\n",
       "  -0.12743474543094635,\n",
       "  -0.5048604607582092,\n",
       "  -0.471625953912735,\n",
       "  0.19957235455513,\n",
       "  0.3579193949699402,\n",
       "  -0.08009441941976547,\n",
       "  0.010041814297437668,\n",
       "  -0.48221009969711304,\n",
       "  0.19295629858970642,\n",
       "  -0.16072118282318115,\n",
       "  0.48191940784454346,\n",
       "  0.22397290170192719,\n",
       "  0.23785580694675446,\n",
       "  0.5573644638061523,\n",
       "  0.013030987232923508,\n",
       "  0.21993489563465118,\n",
       "  0.17214475572109222,\n",
       "  0.8985391855239868,\n",
       "  1.1059409379959106,\n",
       "  -0.6165094375610352,\n",
       "  -0.15247495472431183,\n",
       "  -0.3756446838378906,\n",
       "  -0.23433122038841248,\n",
       "  0.06411436945199966,\n",
       "  -0.1295158565044403,\n",
       "  0.22380417585372925,\n",
       "  -0.6371030807495117,\n",
       "  1.1724536418914795,\n",
       "  -0.04513296112418175,\n",
       "  -0.02387055568397045,\n",
       "  -0.41024717688560486,\n",
       "  0.3714029788970947,\n",
       "  0.07922203093767166,\n",
       "  0.2749096751213074,\n",
       "  -0.02760433219373226,\n",
       "  -0.6063851714134216,\n",
       "  0.3749072551727295,\n",
       "  -0.4484843611717224,\n",
       "  -0.2681480050086975,\n",
       "  0.49209827184677124,\n",
       "  -0.7064786553382874,\n",
       "  0.3814597427845001,\n",
       "  -0.8379508256912231,\n",
       "  -0.10589183866977692,\n",
       "  0.8880450129508972,\n",
       "  -0.4523322582244873,\n",
       "  0.4013178050518036,\n",
       "  0.7524261474609375,\n",
       "  -0.3678078055381775,\n",
       "  1.2483851909637451,\n",
       "  -0.4370359778404236,\n",
       "  -0.21779949963092804,\n",
       "  0.0536472424864769,\n",
       "  0.4341031014919281,\n",
       "  0.31509914994239807,\n",
       "  0.15433916449546814,\n",
       "  0.30003172159194946,\n",
       "  0.031102627515792847,\n",
       "  -0.22313790023326874,\n",
       "  -0.7915427088737488,\n",
       "  0.2622305750846863,\n",
       "  -0.41356760263442993,\n",
       "  -0.08469942957162857,\n",
       "  0.5810692310333252,\n",
       "  -0.4819425940513611,\n",
       "  -0.37441498041152954,\n",
       "  0.7897458672523499,\n",
       "  -0.11677210032939911,\n",
       "  -0.19369973242282867,\n",
       "  0.17002998292446136,\n",
       "  0.3060799837112427,\n",
       "  0.25039854645729065,\n",
       "  0.5973700881004333,\n",
       "  0.09002286940813065,\n",
       "  0.0933876633644104,\n",
       "  0.20862933993339539,\n",
       "  -0.20386505126953125,\n",
       "  -0.00020156119717285037,\n",
       "  0.733384370803833,\n",
       "  -0.3118767738342285,\n",
       "  0.5473107695579529,\n",
       "  -0.06287690252065659,\n",
       "  0.450851708650589,\n",
       "  0.3495155870914459,\n",
       "  0.30077821016311646,\n",
       "  0.1542934775352478,\n",
       "  -0.5043416023254395,\n",
       "  ...]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict['outputs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ff056",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids\n",
    "attention_mask \n",
    "\n",
    "# open file in write mode\n",
    "with open(r'./temp-bloom/input_ids.txt', 'w') as fp:\n",
    "    for item in input_ids:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done input_ids')\n",
    "    \n",
    "# open file in write mode\n",
    "with open(r'./temp-bloom/attention_mask.txt', 'w') as fp:\n",
    "    for item in attention_mask:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done attention_mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d94cc",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "354217b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '42ad8536-8cfd-477b-aee7-43ae516c59fa',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '42ad8536-8cfd-477b-aee7-43ae516c59fa',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 15 Sep 2022 22:25:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sm_client.delete_endpoint(EndpointName=endpoint_name_p5)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name_p5)\n",
    "sm_client.delete_model(ModelName=endpoint_name_p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c22e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# sagemaker\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# triton\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "# transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# custom CloudWatch\n",
    "#from cloudwatch import get_endpoint_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --gpus=all --rm -it  -v `pwd`/workspace:/workspace nvcr.io/nvidia/pytorch:21.08-py3 /bin/bash generate_models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9c1b2",
   "metadata": {},
   "source": [
    "## START MME for triton "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf14555",
   "metadata": {},
   "source": [
    "**Upload first**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf22a4",
   "metadata": {},
   "source": [
    "### Upload multiple copies for MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(1,100):\n",
    "    s3_model_path_triton_mme = sagemaker.s3.S3Uploader().upload(\n",
    "        local_path=\"./triton-serve/model.tar.gz\",\n",
    "        desired_s3_uri=f\"s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc/model-{ii}\",\n",
    "        sagemaker_session=session\n",
    "    )\n",
    "s3_model_path_mme='s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc'\n",
    "print(\"MULTIPLE:Uplodas:\")\n",
    "print(s3_model_path_triton_mme)\n",
    "print(s3_model_path_mme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabfa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fce33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path_mme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e55f7",
   "metadata": {},
   "source": [
    "**Create the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name_p5_mme = name_from_base(f\"p5-bert-uc-mme\")\n",
    "print(endpoint_name_p5_mme)\n",
    "\n",
    "container_p5_mme = {\n",
    "    'Image': triton_image_uri,\n",
    "    'ModelDataUrl': s3_model_path_mme,\n",
    "    'Mode':'MultiModel',\n",
    "    'Environment': {\n",
    "        #'SAGEMAKER_PROGRAM' : 'inference.py',\n",
    "        #'SAGEMAKER_SUBMIT_DIRECTORY' : 'code',\n",
    "        'SAGEMAKER_TRITON_DEFAULT_MODEL_NAME': 'model-1',\n",
    "        \"SAGEMAKER_TRITON_BATCH_SIZE\": \"16\",\n",
    "        \"SAGEMAKER_TRITON_MAX_BATCH_DELAY\": \"1000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_DEFAULT_BYTE_SIZE\" : \"16777216\", #\"16777216000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_GROWTH_BYTE_SIZE\": \"1048576\"\n",
    "    }\n",
    "}\n",
    "create_model_response_mme = sm_client.create_model(\n",
    "    ModelName=endpoint_name_p5_mme, ExecutionRoleArn=role, PrimaryContainer=container_p5_mme\n",
    ")\n",
    "print(create_model_response_mme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922543f",
   "metadata": {},
   "source": [
    "**Create the Endpoint config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02540ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_config_response_mme = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_name_p5_mme,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\", #\"ml.g4dn.xlarge\",ml.g5.8xlarge\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": endpoint_name_p5_mme,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response_mme[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05b7b4",
   "metadata": {},
   "source": [
    "**Create the endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee53f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response_mme = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name_p5_mme, EndpointConfigName=endpoint_name_p5_mme\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response_mme[\"EndpointArn\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbe4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5_mme)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"MME:Model:endpoint:Triton:Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5_mme)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"MME:model:triton:Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"MME:model:triton:Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21893df",
   "metadata": {},
   "source": [
    "**Test the end point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "max_seq_length=512\n",
    "text_triton = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\"\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5_mme, ContentType=\"application/octet-stream\", Body=json.dumps(payload), TargetModel  = \"/model-9/model.tar.gz\"\n",
    ")\n",
    "\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "output_dict.keys()\n",
    "\n",
    "enc.decode(output_dict['outputs'][0]['data'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name_p5_mme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ad7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5_mme, ContentType=\"text/json\", Body=json.dumps(payload), TargetModel  = \"/model-9/model.tar.gz\"\n",
    ")\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "output_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce4ee9",
   "metadata": {},
   "source": [
    "**set up in S3 payload to be used for inference load testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9234c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length=512\n",
    "text_triton = \"\"\"\n",
    "                Create payload JSON and upload it on S3. \n",
    "                This will be used by Inference Recommender to run the load test.\n",
    "              \"\"\"\n",
    "\n",
    "input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Sample payload to be used with Inference Recommender\")\n",
    "print(payload)\n",
    "\n",
    "payload_location = \"./sample-payload/\"\n",
    "!mkdir -p $payload_location\n",
    "\n",
    "payload_archive_name = \"payload.tar.gz\"\n",
    "\n",
    "with open(payload_location + \"request.json\", \"w\") as f:\n",
    "    json.dump(payload, f)\n",
    "\n",
    "\n",
    "!cd ./sample-payload/ && tar czvf ../payload.tar.gz *\n",
    "\n",
    "print(f\"payload.tar.gz created at {payload_location}/{payload_archive_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485d384",
   "metadata": {},
   "source": [
    "**Upload sample payload to S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_sample_data_path_triton = sagemaker.s3.S3Uploader().upload(\n",
    "    local_path=f\"{payload_archive_name}\",\n",
    "    desired_s3_uri=\"s3://sagemaker-us-east-1-622343165275/bloom/triton_test_data\",\n",
    "    sagemaker_session=session\n",
    ")\n",
    "s3_sample_data_path_triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b563b",
   "metadata": {},
   "source": [
    "## Inference Load test set up\n",
    "### DOES NOT WORK FOR MME -- SO SKIP this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_domain = \"NATURAL_LANGUAGE_PROCESSING\"\n",
    "ml_task = \"FILL_MASK\"\n",
    "ml_framework = \"PYTORCH\"\n",
    "framework_version = \"1.6.0\"\n",
    "model_tested = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d75cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = \"pt-triton-benchmark-model-\" + ts\n",
    "model_package_group_name = \"pt-triton-benchmark-model-group-\" + ts\n",
    "advanced_job = \"pt-triton-benchmark-advanced-job-\" + ts\n",
    "\n",
    "print(f\"SageMaker Model Name: {sm_model_name}\")\n",
    "print(f\"SageMaker Mode Package Name: {model_package_group_name}\")\n",
    "print(f\"SageMaker Advanced Job Name: {advanced_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path_mme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_infrec_mme = {\n",
    "    'Image': triton_image_uri,\n",
    "    \"NearestModelName\": model_tested, #'model-1',\n",
    "    \"Framework\": ml_framework,\n",
    "    'ModelDataUrl': s3_model_path_mme,\n",
    "    #'Mode':'MultiModel',\n",
    "    'Environment': {\n",
    "        #'SAGEMAKER_PROGRAM' : 'inference.py',\n",
    "        #'SAGEMAKER_SUBMIT_DIRECTORY' : 'code',\n",
    "        'SAGEMAKER_TRITON_DEFAULT_MODEL_NAME': 'model-1',\n",
    "        \"SAGEMAKER_TRITON_BATCH_SIZE\": \"16\",\n",
    "        \"SAGEMAKER_TRITON_MAX_BATCH_DELAY\": \"1000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_DEFAULT_BYTE_SIZE\" : \"16777216\", #\"16777216000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_GROWTH_BYTE_SIZE\": \"1048576\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c32a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pacakge_group_response = sm_client.create_model_package_group(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageGroupDescription=\"BERT large uncased Model group for Triton Serving\",\n",
    ")\n",
    "print(f\"Model Registry package group: {model_pacakge_group_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_version_response = sm_client.create_model_package(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageDescription=\"BERT large uncased Model group for Triton Serving\",\n",
    "    Domain=ml_domain,\n",
    "    Task=ml_task,\n",
    "    SamplePayloadUrl=s3_sample_data_path_triton,\n",
    "    InferenceSpecification={\n",
    "        \"Containers\": [container_infrec_mme],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\n",
    "            \"ml.g4dn.4xlarge\",\n",
    "            \"ml.g4dn.4xlarge\",\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"application/octet-stream\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"application/json\"],\n",
    "    },\n",
    ")\n",
    "model_package_version_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6adcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_response = sm_client.create_inference_recommendations_job(\n",
    "    JobName=advanced_job,\n",
    "    JobDescription=\"nlp triton Inference Advanced Recommender Job\",\n",
    "    JobType=\"Advanced\",\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        \"ModelPackageVersionArn\": model_package_version_response[\"ModelPackageArn\"],\n",
    "        \"JobDurationInSeconds\": 7200,\n",
    "        \"EndpointConfigurations\": [\n",
    "            #{\"InstanceType\": \"ml.p3.8xlarge\"},\n",
    "            #{\"InstanceType\": \"ml.p3.2xlarge\"},\n",
    "            {\"InstanceType\": \"ml.p2.16xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.8xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.4xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.2xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.12xlarge\"},\n",
    "        ],\n",
    "        \"TrafficPattern\": {\n",
    "            \"TrafficType\": \"PHASES\",\n",
    "            \"Phases\": [\n",
    "                {\n",
    "                    \"InitialNumberOfUsers\": 2,\n",
    "                    \"SpawnRate\": 3,\n",
    "                    \"DurationInSeconds\": 900,\n",
    "                },  # simulating 50 users, 2 initial and 3 new users every minute for 16 minutes\n",
    "            ],  # second phase, we will strt with 50 users, steady traffic for 5 minutes\n",
    "        },\n",
    "        \"ResourceLimit\": {\"MaxNumberOfTests\": 10, \"MaxParallelOfTests\": 5},\n",
    "    },\n",
    "    StoppingConditions={\n",
    "        \"MaxInvocations\": 30000,\n",
    "        \"ModelLatencyThresholds\": [{\"Percentile\": \"P95\", \"ValueInMilliseconds\": 500}],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(advanced_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac6b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ended = False\n",
    "while not ended:\n",
    "    inference_recommender_job = sm_client.describe_inference_recommendations_job(\n",
    "        JobName=str(advanced_job)\n",
    "    )\n",
    "    if inference_recommender_job[\"Status\"] in [\"COMPLETED\", \"STOPPED\", \"FAILED\"]:\n",
    "        print(f\"Inference recommender job status: {inference_recommender_job['Status']} \")\n",
    "        ended = True\n",
    "    else:\n",
    "        print(\"Inference recommender job in progress\")\n",
    "        time.sleep(300)\n",
    "\n",
    "if inference_recommender_job[\"Status\"] == \"FAILED\":\n",
    "    print(\"Inference recommender job failed \")\n",
    "    print(\"Failed Reason: {}\".inference_recommender_job[\"FailedReason\"])\n",
    "else:\n",
    "    print(\"Inference recommender job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc3df2",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038729e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e062114",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name_p5_mme)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name_p5_mme)\n",
    "sm_client.delete_model(ModelName=endpoint_name_p5_mme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cdb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
