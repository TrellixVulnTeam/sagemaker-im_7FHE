{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0fe4577",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting boto3==1.24.68\n",
      "  Downloading boto3-1.24.68-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: botocore<1.28.0,>=1.27.68 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3==1.24.68) (1.27.84)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3==1.24.68) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3==1.24.68) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.68->boto3==1.24.68) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.68->boto3==1.24.68) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.68->boto3==1.24.68) (1.16.0)\n",
      "Installing collected packages: boto3\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.24.79\n",
      "    Uninstalling boto3-1.24.79:\n",
      "      Successfully uninstalled boto3-1.24.79\n",
      "Successfully installed boto3-1.24.68\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install boto3==1.24.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dcc6283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.0-deepspeed: Pulling from deepjavalibrary/djl-serving\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "602a45a9c0c5: Pulling fs layer\n",
      "e1bae4c1f40f: Pulling fs layer\n",
      "d9d586ab2510: Pulling fs layer\n",
      "2b44adc78060: Pulling fs layer\n",
      "cd4d84563a60: Pulling fs layer\n",
      "e19a4e23074d: Pulling fs layer\n",
      "a69bd65705b8: Pulling fs layer\n",
      "7145f7b4815b: Pulling fs layer\n",
      "e367c0f08642: Pulling fs layer\n",
      "eee5fed2d5ca: Pulling fs layer\n",
      "46b22735db66: Pulling fs layer\n",
      "dc2cc42a02f3: Pulling fs layer\n",
      "41ae858b91d1: Pulling fs layer\n",
      "d46f0903e5a5: Pulling fs layer\n",
      "3cb1e2965cce: Pulling fs layer\n",
      "0391b9b1de9f: Pulling fs layer\n",
      "d4d8280fcfac: Pulling fs layer\n",
      "eee5fed2d5ca: Waiting\n",
      "46b22735db66: Waiting\n",
      "dc2cc42a02f3: Waiting\n",
      "41ae858b91d1: Waiting\n",
      "d46f0903e5a5: Waiting\n",
      "3cb1e2965cce: Waiting\n",
      "0391b9b1de9f: Waiting\n",
      "d4d8280fcfac: Waiting\n",
      "d9d586ab2510: Waiting\n",
      "2b44adc78060: Waiting\n",
      "cd4d84563a60: Waiting\n",
      "e19a4e23074d: Waiting\n",
      "a69bd65705b8: Waiting\n",
      "7145f7b4815b: Waiting\n",
      "e367c0f08642: Waiting\n",
      "602a45a9c0c5: Verifying Checksum\n",
      "602a45a9c0c5: Download complete\n",
      "e1bae4c1f40f: Verifying Checksum\n",
      "e1bae4c1f40f: Download complete\n",
      "d5fd17ec1767: Verifying Checksum\n",
      "d5fd17ec1767: Download complete\n",
      "2b44adc78060: Verifying Checksum\n",
      "2b44adc78060: Download complete\n",
      "d9d586ab2510: Verifying Checksum\n",
      "d9d586ab2510: Download complete\n",
      "e19a4e23074d: Download complete\n",
      "7145f7b4815b: Verifying Checksum\n",
      "7145f7b4815b: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "602a45a9c0c5: Pull complete\n",
      "e1bae4c1f40f: Pull complete\n",
      "d9d586ab2510: Pull complete\n",
      "2b44adc78060: Pull complete\n",
      "cd4d84563a60: Verifying Checksum\n",
      "cd4d84563a60: Download complete\n",
      "eee5fed2d5ca: Verifying Checksum\n",
      "eee5fed2d5ca: Download complete\n",
      "46b22735db66: Verifying Checksum\n",
      "46b22735db66: Download complete\n",
      "dc2cc42a02f3: Verifying Checksum\n",
      "dc2cc42a02f3: Download complete\n",
      "41ae858b91d1: Verifying Checksum\n",
      "41ae858b91d1: Download complete\n",
      "d46f0903e5a5: Download complete\n",
      "3cb1e2965cce: Verifying Checksum\n",
      "3cb1e2965cce: Download complete\n",
      "a69bd65705b8: Verifying Checksum\n",
      "a69bd65705b8: Download complete\n",
      "0391b9b1de9f: Verifying Checksum\n",
      "0391b9b1de9f: Download complete\n",
      "e367c0f08642: Verifying Checksum\n",
      "e367c0f08642: Download complete\n",
      "d4d8280fcfac: Verifying Checksum\n",
      "d4d8280fcfac: Download complete\n",
      "cd4d84563a60: Pull complete\n",
      "e19a4e23074d: Pull complete\n",
      "a69bd65705b8: Pull complete\n",
      "7145f7b4815b: Pull complete\n",
      "e367c0f08642: Pull complete\n",
      "eee5fed2d5ca: Pull complete\n",
      "46b22735db66: Pull complete\n",
      "dc2cc42a02f3: Pull complete\n",
      "41ae858b91d1: Pull complete\n",
      "d46f0903e5a5: Pull complete\n",
      "3cb1e2965cce: Pull complete\n",
      "0391b9b1de9f: Pull complete\n",
      "d4d8280fcfac: Pull complete\n",
      "Digest: sha256:41848dffa70483c3af8b2420135c0e0d6b5e32c6cd21d2cef94e10b0bae6fe47\n",
      "Status: Downloaded newer image for deepjavalibrary/djl-serving:0.18.0-deepspeed\n",
      "docker.io/deepjavalibrary/djl-serving:0.18.0-deepspeed\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "docker pull deepjavalibrary/djl-serving:0.18.0-deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45fc5510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                   TAG                IMAGE ID       CREATED        SIZE\n",
      "catboost-sagemaker-multimodel                                                latest             befea775c8ef   12 hours ago   1.35GB\n",
      "874199810560.dkr.ecr.us-east-1.amazonaws.com/catboost-sagemaker-multimodel   latest             befea775c8ef   12 hours ago   1.35GB\n",
      "ubuntu                                                                       18.04              35b3f4f76a24   3 weeks ago    63.1MB\n",
      "deepjavalibrary/djl-serving                                                  0.18.0-deepspeed   c2edba9c6d73   2 months ago   12.7GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8359bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [874199810560.dkr.ecr.us-east-1.amazonaws.com/djl_deepspeed]\n",
      "42737ae997a9: Preparing\n",
      "4e257e38b819: Preparing\n",
      "b16fc1914e14: Preparing\n",
      "7e20e12fff52: Preparing\n",
      "01b6a2323efe: Preparing\n",
      "55df8d287560: Preparing\n",
      "61d781c1452a: Preparing\n",
      "dbc3bf935e02: Preparing\n",
      "1a5fac543081: Preparing\n",
      "a8d0c4c62eef: Preparing\n",
      "7ed9a71261c7: Preparing\n",
      "a1eeba43cdbe: Preparing\n",
      "6127942867a5: Preparing\n",
      "e592fe6d10a9: Preparing\n",
      "f42691182163: Preparing\n",
      "68016c5bb65c: Preparing\n",
      "8034550a3bbe: Preparing\n",
      "bf8cedc62fb3: Preparing\n",
      "7ed9a71261c7: Waiting\n",
      "a1eeba43cdbe: Waiting\n",
      "6127942867a5: Waiting\n",
      "e592fe6d10a9: Waiting\n",
      "f42691182163: Waiting\n",
      "68016c5bb65c: Waiting\n",
      "8034550a3bbe: Waiting\n",
      "bf8cedc62fb3: Waiting\n",
      "61d781c1452a: Waiting\n",
      "dbc3bf935e02: Waiting\n",
      "1a5fac543081: Waiting\n",
      "a8d0c4c62eef: Waiting\n",
      "55df8d287560: Waiting\n",
      "01b6a2323efe: Pushed\n",
      "7e20e12fff52: Pushed\n",
      "b16fc1914e14: Pushed\n",
      "61d781c1452a: Pushed\n",
      "55df8d287560: Pushed\n",
      "dbc3bf935e02: Pushed\n",
      "a8d0c4c62eef: Pushed\n",
      "a1eeba43cdbe: Pushed\n",
      "4e257e38b819: Pushed\n",
      "e592fe6d10a9: Pushed\n",
      "f42691182163: Pushed\n",
      "68016c5bb65c: Pushed\n",
      "8034550a3bbe: Pushed\n",
      "bf8cedc62fb3: Pushed\n",
      "6127942867a5: Pushed\n",
      "7ed9a71261c7: Pushed\n",
      "1a5fac543081: Pushed\n",
      "42737ae997a9: Pushed\n",
      "latest: digest: sha256:41848dffa70483c3af8b2420135c0e0d6b5e32c6cd21d2cef94e10b0bae6fe47 size: 4098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our container\n",
    "img=djl_deepspeed\n",
    "\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration\n",
    "region=$(aws configure get region)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${img}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${img}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${img}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "\n",
    "# # Build the docker image locally with the image name and then push it to ECR\n",
    "docker tag deepjavalibrary/djl-serving:0.18.0-deepspeed ${fullname}\n",
    "\n",
    "docker push $fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f117f",
   "metadata": {},
   "source": [
    "#### Write Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b933855",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p djl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113d483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing djl/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile djl/model.py\n",
    "\n",
    "from djl_python import Input, Output\n",
    "import os\n",
    "import deepspeed\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "predictor = None\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model_name = \"EleutherAI/gpt-j-6B\"\n",
    "    tensor_parallel = int(os.getenv(\"TENSOR_PARALLEL_DEGREE\", \"2\"))\n",
    "    local_rank = int(os.getenv(\"LOCAL_RANK\", \"0\"))\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, revision=\"float32\", torch_dtype=torch.float32\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = deepspeed.init_inference(\n",
    "        model,\n",
    "        mp_size=tensor_parallel,\n",
    "        dtype=model.dtype,\n",
    "        replace_method=\"auto\",\n",
    "        replace_with_kernel_inject=True,\n",
    "    )\n",
    "    generator = pipeline(\n",
    "        task=\"text-generation\", model=model, tokenizer=tokenizer, device=local_rank\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "\n",
    "def handle(inputs: Input) -> None:\n",
    "    global predictor\n",
    "    if not predictor:\n",
    "        predictor = get_model()\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "\n",
    "    data = inputs.get_as_string()\n",
    "    result = predictor(data, do_sample=True, min_tokens=200, max_new_tokens=256)\n",
    "    return Output().add(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c9b64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing djl/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile djl/serving.properties\n",
    "engine = Rubikon\n",
    "gpu.minWorkers=1\n",
    "gpu.maxWorkers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec48904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "\n",
    "session = sagemaker.Session()\n",
    "account = session.account_id()\n",
    "region = session.boto_region_name\n",
    "img = \"djl_deepspeed\"\n",
    "fullname = account + \".dkr.ecr.\" + region + \".amazonaws.com/\" + img + \":latest\"\n",
    "bucket = session.default_bucket()\n",
    "path = \"s3://\" + bucket + \"/DEMO-djl-big-model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef977b6",
   "metadata": {},
   "source": [
    "#### Tar structure"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b06a59b1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "model.tar.gz/\n",
    "\n",
    "|- djl\n",
    "|- model.py\n",
    "|- serving.properties\n",
    "|- code/\n",
    "  |- inference.py\n",
    "  |- requirements.txt \n",
    "  \n",
    "transform_fn(model, data, content_type, accept_type): Overrides the default transform function with custom implementation. \n",
    "    Customers using this would have to implement preprocess, predict and \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd7e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "djl/\n",
      "djl/model.py\n",
      "djl/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "rm gpt-j.tar.gz\n",
    "#always start fresh\n",
    "\n",
    "#mkdir -p gpt-j\n",
    "#mv model.py gpt-j\n",
    "#mv serving.properties gpt-j\n",
    "tar -czvf gpt-j.tar.gz djl/\n",
    "#aws s3 cp gpt-j.tar.gz {path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12730508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-874199810560/DEMO-djl-big-model/gpt-j.tar.gz'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s3_url = sagemaker.s3.S3Uploader.upload(\n",
    "    \"gpt-j.tar.gz\", path, kms_key=None, sagemaker_session=session\n",
    ")\n",
    "model_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd943edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_name = \"gpt-j-\" + time_stamp\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=session.get_caller_identity_arn(),\n",
    "    PrimaryContainer={\n",
    "        \"Image\": fullname,\n",
    "        \"ModelDataUrl\": model_s3_url,\n",
    "        \"Environment\": {\"TENSOR_PARALLEL_DEGREE\": \"2\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c1784",
   "metadata": {},
   "source": [
    "Now we create an endpoint configuration that SageMaker hosting services uses to deploy models. Note that we configured ModelDataDownloadTimeoutInSeconds and ContainerStartupHealthCheckTimeoutInSeconds to accommodate the large size of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa05229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:874199810560:endpoint-config/t-j-config-2022-10-02-19-45-08',\n",
       " 'ResponseMetadata': {'RequestId': '952b2a36-2f43-4177-bb36-0ae71d44af93',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '952b2a36-2f43-4177-bb36-0ae71d44af93',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '111',\n",
       "   'date': 'Sun, 02 Oct 2022 19:45:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_instance_count = 1\n",
    "instance_type = \"ml.p3.2xlarge\" # \"ml.g5.48xlarge\"\n",
    "variant_name = \"AllTraffic\"\n",
    "endpoint_config_name = \"t-j-config-\" + time_stamp\n",
    "\n",
    "production_variants = [\n",
    "    {\n",
    "        \"VariantName\": variant_name,\n",
    "        \"ModelName\": model_name,\n",
    "        \"InitialInstanceCount\": initial_instance_count,\n",
    "        \"InstanceType\": instance_type,\n",
    "        \"ModelDataDownloadTimeoutInSeconds\": 1800,\n",
    "        \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600,\n",
    "    }\n",
    "]\n",
    "\n",
    "endpoint_config = {\n",
    "    \"EndpointConfigName\": endpoint_config_name,\n",
    "    \"ProductionVariants\": production_variants,\n",
    "}\n",
    "\n",
    "ep_conf_res = sm_client.create_endpoint_config(**endpoint_config)\n",
    "ep_conf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00e0759f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointArn': 'arn:aws:sagemaker:us-east-1:874199810560:endpoint/gpt-j2022-10-02-19-45-08',\n",
       " 'ResponseMetadata': {'RequestId': '7644b098-7d61-4595-b513-6adb218b04c5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7644b098-7d61-4595-b513-6adb218b04c5',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '92',\n",
       "   'date': 'Sun, 02 Oct 2022 19:45:09 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = \"gpt-j\" + time_stamp\n",
    "ep_res = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "ep_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac8fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for gpt-j2022-10-02-19-45-08 endpoint to be in service...\n"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for {} endpoint to be in service...\".format(endpoint_name))\n",
    "waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "print(\"Created {} endpoint is in Service and read to invoke ...\".format(endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2befe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "content_type = \"text/plain\"  # The MIME type of the input data in the request body.\n",
    "payload = \"Amazon.com is the best\"  # Payload for inference.\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=content_type, Body=payload\n",
    ")\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf63426",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
